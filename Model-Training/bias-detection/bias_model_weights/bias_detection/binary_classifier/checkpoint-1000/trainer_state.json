{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.8461538461538463,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038461538461538464,
      "grad_norm": 2.360055685043335,
      "learning_rate": 1.9861538461538465e-05,
      "loss": 0.4127,
      "step": 10
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 0.5003295540809631,
      "learning_rate": 1.970769230769231e-05,
      "loss": 0.0729,
      "step": 20
    },
    {
      "epoch": 0.11538461538461539,
      "grad_norm": 0.1709214448928833,
      "learning_rate": 1.9553846153846155e-05,
      "loss": 0.0163,
      "step": 30
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.09590094536542892,
      "learning_rate": 1.94e-05,
      "loss": 0.0069,
      "step": 40
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 0.0698404610157013,
      "learning_rate": 1.924615384615385e-05,
      "loss": 0.0041,
      "step": 50
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 0.05137713998556137,
      "learning_rate": 1.9092307692307695e-05,
      "loss": 0.0029,
      "step": 60
    },
    {
      "epoch": 0.2692307692307692,
      "grad_norm": 0.03879096359014511,
      "learning_rate": 1.893846153846154e-05,
      "loss": 0.0021,
      "step": 70
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.034655798226594925,
      "learning_rate": 1.8784615384615385e-05,
      "loss": 0.0018,
      "step": 80
    },
    {
      "epoch": 0.34615384615384615,
      "grad_norm": 0.02873547375202179,
      "learning_rate": 1.8630769230769234e-05,
      "loss": 0.0015,
      "step": 90
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 0.024518657475709915,
      "learning_rate": 1.847692307692308e-05,
      "loss": 0.0012,
      "step": 100
    },
    {
      "epoch": 0.4230769230769231,
      "grad_norm": 0.023187197744846344,
      "learning_rate": 1.8323076923076924e-05,
      "loss": 0.001,
      "step": 110
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.021889539435505867,
      "learning_rate": 1.816923076923077e-05,
      "loss": 0.0009,
      "step": 120
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.01791432499885559,
      "learning_rate": 1.8015384615384618e-05,
      "loss": 0.0008,
      "step": 130
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 0.01599976420402527,
      "learning_rate": 1.7861538461538464e-05,
      "loss": 0.0007,
      "step": 140
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 0.013448075391352177,
      "learning_rate": 1.770769230769231e-05,
      "loss": 0.0006,
      "step": 150
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.012151126749813557,
      "learning_rate": 1.7553846153846154e-05,
      "loss": 0.0006,
      "step": 160
    },
    {
      "epoch": 0.6538461538461539,
      "grad_norm": 0.010742530226707458,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.0005,
      "step": 170
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 0.011449769139289856,
      "learning_rate": 1.7246153846153848e-05,
      "loss": 0.0005,
      "step": 180
    },
    {
      "epoch": 0.7307692307692307,
      "grad_norm": 0.00954568199813366,
      "learning_rate": 1.7092307692307693e-05,
      "loss": 0.0004,
      "step": 190
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.009510491043329239,
      "learning_rate": 1.693846153846154e-05,
      "loss": 0.0004,
      "step": 200
    },
    {
      "epoch": 0.8076923076923077,
      "grad_norm": 0.009686414152383804,
      "learning_rate": 1.6784615384615387e-05,
      "loss": 0.0004,
      "step": 210
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 0.0068610296584665775,
      "learning_rate": 1.6630769230769233e-05,
      "loss": 0.0003,
      "step": 220
    },
    {
      "epoch": 0.8846153846153846,
      "grad_norm": 0.006065954454243183,
      "learning_rate": 1.6476923076923078e-05,
      "loss": 0.0003,
      "step": 230
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 0.006182481534779072,
      "learning_rate": 1.6323076923076923e-05,
      "loss": 0.0003,
      "step": 240
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 0.0068014273419976234,
      "learning_rate": 1.6169230769230772e-05,
      "loss": 0.0002,
      "step": 250
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.004898023791611195,
      "learning_rate": 1.6015384615384617e-05,
      "loss": 0.0002,
      "step": 260
    },
    {
      "epoch": 1.0384615384615385,
      "grad_norm": 0.005388251040130854,
      "learning_rate": 1.5861538461538462e-05,
      "loss": 0.0002,
      "step": 270
    },
    {
      "epoch": 1.0769230769230769,
      "grad_norm": 0.005809964146465063,
      "learning_rate": 1.5707692307692308e-05,
      "loss": 0.0002,
      "step": 280
    },
    {
      "epoch": 1.1153846153846154,
      "grad_norm": 0.0038387631066143513,
      "learning_rate": 1.5553846153846156e-05,
      "loss": 0.0002,
      "step": 290
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.004227310419082642,
      "learning_rate": 1.54e-05,
      "loss": 0.0002,
      "step": 300
    },
    {
      "epoch": 1.1923076923076923,
      "grad_norm": 0.004361880477517843,
      "learning_rate": 1.5246153846153849e-05,
      "loss": 0.0002,
      "step": 310
    },
    {
      "epoch": 1.2307692307692308,
      "grad_norm": 0.0045808530412614346,
      "learning_rate": 1.5092307692307692e-05,
      "loss": 0.0002,
      "step": 320
    },
    {
      "epoch": 1.2692307692307692,
      "grad_norm": 0.004152283538132906,
      "learning_rate": 1.493846153846154e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 0.003971251193434,
      "learning_rate": 1.4784615384615386e-05,
      "loss": 0.0001,
      "step": 340
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 0.0034561401698738337,
      "learning_rate": 1.4630769230769233e-05,
      "loss": 0.0001,
      "step": 350
    },
    {
      "epoch": 1.3846153846153846,
      "grad_norm": 0.003921054303646088,
      "learning_rate": 1.4476923076923077e-05,
      "loss": 0.0001,
      "step": 360
    },
    {
      "epoch": 1.4230769230769231,
      "grad_norm": 0.0030305180698633194,
      "learning_rate": 1.4323076923076924e-05,
      "loss": 0.0001,
      "step": 370
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 0.0025280893314629793,
      "learning_rate": 1.416923076923077e-05,
      "loss": 0.0001,
      "step": 380
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.0031613591127097607,
      "learning_rate": 1.4015384615384618e-05,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.0026828499976545572,
      "learning_rate": 1.3861538461538461e-05,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 1.5769230769230769,
      "grad_norm": 0.002706849481910467,
      "learning_rate": 1.3707692307692308e-05,
      "loss": 0.0001,
      "step": 410
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.00231526349671185,
      "learning_rate": 1.3553846153846155e-05,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 1.6538461538461537,
      "grad_norm": 0.002930247923359275,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 1.6923076923076923,
      "grad_norm": 0.002495194086804986,
      "learning_rate": 1.3246153846153846e-05,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 0.002112348098307848,
      "learning_rate": 1.3092307692307693e-05,
      "loss": 0.0001,
      "step": 450
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 0.0024410621263086796,
      "learning_rate": 1.293846153846154e-05,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 1.8076923076923077,
      "grad_norm": 0.0024000676348805428,
      "learning_rate": 1.2784615384615387e-05,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 1.8461538461538463,
      "grad_norm": 0.0022834106348454952,
      "learning_rate": 1.263076923076923e-05,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 1.8846153846153846,
      "grad_norm": 0.0018459578277543187,
      "learning_rate": 1.2476923076923077e-05,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.0018737738719210029,
      "learning_rate": 1.2323076923076924e-05,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 1.9615384615384617,
      "grad_norm": 0.0017001760425046086,
      "learning_rate": 1.2169230769230771e-05,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0018124631606042385,
      "learning_rate": 1.2015384615384615e-05,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 2.0384615384615383,
      "grad_norm": 0.0022018016315996647,
      "learning_rate": 1.1861538461538462e-05,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 2.076923076923077,
      "grad_norm": 0.0018828578758984804,
      "learning_rate": 1.1707692307692309e-05,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 2.1153846153846154,
      "grad_norm": 0.0017981070559471846,
      "learning_rate": 1.1553846153846156e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 2.1538461538461537,
      "grad_norm": 0.0016691471682861447,
      "learning_rate": 1.14e-05,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 2.1923076923076925,
      "grad_norm": 0.0018679635832086205,
      "learning_rate": 1.1246153846153846e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 2.230769230769231,
      "grad_norm": 0.0018955126870423555,
      "learning_rate": 1.1092307692307693e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 2.269230769230769,
      "grad_norm": 0.0013722579460591078,
      "learning_rate": 1.093846153846154e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.001576230046339333,
      "learning_rate": 1.0784615384615384e-05,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 2.3461538461538463,
      "grad_norm": 0.0015702631790190935,
      "learning_rate": 1.063076923076923e-05,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 2.3846153846153846,
      "grad_norm": 0.0013717843685299158,
      "learning_rate": 1.0476923076923078e-05,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 2.423076923076923,
      "grad_norm": 0.001603985670953989,
      "learning_rate": 1.0323076923076925e-05,
      "loss": 0.0,
      "step": 630
    },
    {
      "epoch": 2.4615384615384617,
      "grad_norm": 0.0014736767625436187,
      "learning_rate": 1.0169230769230768e-05,
      "loss": 0.0,
      "step": 640
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.0012330124154686928,
      "learning_rate": 1.0015384615384615e-05,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 2.5384615384615383,
      "grad_norm": 0.0012195906601846218,
      "learning_rate": 9.861538461538462e-06,
      "loss": 0.0,
      "step": 660
    },
    {
      "epoch": 2.5769230769230766,
      "grad_norm": 0.0015741749666631222,
      "learning_rate": 9.707692307692308e-06,
      "loss": 0.0,
      "step": 670
    },
    {
      "epoch": 2.6153846153846154,
      "grad_norm": 0.0013020177138969302,
      "learning_rate": 9.553846153846155e-06,
      "loss": 0.0,
      "step": 680
    },
    {
      "epoch": 2.6538461538461537,
      "grad_norm": 0.0013672409113496542,
      "learning_rate": 9.4e-06,
      "loss": 0.0,
      "step": 690
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.001352545339614153,
      "learning_rate": 9.246153846153847e-06,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 2.730769230769231,
      "grad_norm": 0.0010816664434969425,
      "learning_rate": 9.092307692307692e-06,
      "loss": 0.0,
      "step": 710
    },
    {
      "epoch": 2.769230769230769,
      "grad_norm": 0.0009548033704049885,
      "learning_rate": 8.938461538461539e-06,
      "loss": 0.0,
      "step": 720
    },
    {
      "epoch": 2.8076923076923075,
      "grad_norm": 0.001333781168796122,
      "learning_rate": 8.784615384615386e-06,
      "loss": 0.0,
      "step": 730
    },
    {
      "epoch": 2.8461538461538463,
      "grad_norm": 0.001112749450840056,
      "learning_rate": 8.630769230769231e-06,
      "loss": 0.0,
      "step": 740
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 0.0010452303104102612,
      "learning_rate": 8.476923076923078e-06,
      "loss": 0.0,
      "step": 750
    },
    {
      "epoch": 2.9230769230769234,
      "grad_norm": 0.0011179766152054071,
      "learning_rate": 8.323076923076924e-06,
      "loss": 0.0,
      "step": 760
    },
    {
      "epoch": 2.9615384615384617,
      "grad_norm": 0.0009848764166235924,
      "learning_rate": 8.16923076923077e-06,
      "loss": 0.0,
      "step": 770
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0011348138796165586,
      "learning_rate": 8.015384615384616e-06,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 3.0384615384615383,
      "grad_norm": 0.0010853295680135489,
      "learning_rate": 7.861538461538463e-06,
      "loss": 0.0,
      "step": 790
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.0010968440910801291,
      "learning_rate": 7.707692307692308e-06,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 3.1153846153846154,
      "grad_norm": 0.0012844286393374205,
      "learning_rate": 7.553846153846155e-06,
      "loss": 0.0,
      "step": 810
    },
    {
      "epoch": 3.1538461538461537,
      "grad_norm": 0.0011917433002963662,
      "learning_rate": 7.4e-06,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 3.1923076923076925,
      "grad_norm": 0.0008560391725040972,
      "learning_rate": 7.246153846153847e-06,
      "loss": 0.0,
      "step": 830
    },
    {
      "epoch": 3.230769230769231,
      "grad_norm": 0.001159982057288289,
      "learning_rate": 7.0923076923076926e-06,
      "loss": 0.0,
      "step": 840
    },
    {
      "epoch": 3.269230769230769,
      "grad_norm": 0.0009948847582563758,
      "learning_rate": 6.9384615384615395e-06,
      "loss": 0.0,
      "step": 850
    },
    {
      "epoch": 3.3076923076923075,
      "grad_norm": 0.0008557716500945389,
      "learning_rate": 6.784615384615385e-06,
      "loss": 0.0,
      "step": 860
    },
    {
      "epoch": 3.3461538461538463,
      "grad_norm": 0.0008595489198341966,
      "learning_rate": 6.630769230769232e-06,
      "loss": 0.0,
      "step": 870
    },
    {
      "epoch": 3.3846153846153846,
      "grad_norm": 0.0011391023872420192,
      "learning_rate": 6.476923076923077e-06,
      "loss": 0.0,
      "step": 880
    },
    {
      "epoch": 3.423076923076923,
      "grad_norm": 0.0010735749965533614,
      "learning_rate": 6.323076923076924e-06,
      "loss": 0.0,
      "step": 890
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 0.0007547898567281663,
      "learning_rate": 6.169230769230769e-06,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.0008729891269467771,
      "learning_rate": 6.015384615384616e-06,
      "loss": 0.0,
      "step": 910
    },
    {
      "epoch": 3.5384615384615383,
      "grad_norm": 0.0008629574440419674,
      "learning_rate": 5.861538461538462e-06,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 3.5769230769230766,
      "grad_norm": 0.0008005532436072826,
      "learning_rate": 5.7076923076923086e-06,
      "loss": 0.0,
      "step": 930
    },
    {
      "epoch": 3.6153846153846154,
      "grad_norm": 0.0008252815459854901,
      "learning_rate": 5.553846153846154e-06,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 3.6538461538461537,
      "grad_norm": 0.0010646460577845573,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 3.6923076923076925,
      "grad_norm": 0.000795484462287277,
      "learning_rate": 5.246153846153846e-06,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 3.730769230769231,
      "grad_norm": 0.0009507723734714091,
      "learning_rate": 5.092307692307693e-06,
      "loss": 0.0,
      "step": 970
    },
    {
      "epoch": 3.769230769230769,
      "grad_norm": 0.000935942807700485,
      "learning_rate": 4.938461538461538e-06,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 3.8076923076923075,
      "grad_norm": 0.0008591029909439385,
      "learning_rate": 4.7846153846153845e-06,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.0008426783606410027,
      "learning_rate": 4.630769230769231e-06,
      "loss": 0.0,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1059739189248000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
