{"text": "A legal service firm uses an AI system to automatically generate legal documents and contract analyses without disclosing to clients that the outputs are generated by an AI, and the system lacks mechanisms to explain its decision-making process.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI's involvement and Article 52 (high-risk AI systems) by not providing sufficient transparency about the system's functioning, which is critical in legal services where decisions can significantly impact users' rights.", "context": "legal services"}
{"text": "An e-commerce platform uses an AI system to generate synthetic product reviews and star ratings, which are then displayed alongside genuine user reviews, without disclosing the AI-generated content to consumers.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the use of AI systems in generating reviews, and Article 52 (high-risk AI systems) by deceiving consumers and undermining trust in the marketplace. The lack of transparency prevents users from making informed decisions.", "context": "e-commerce"}
{"text": "A social media platform uses an AI system to generate personalized content recommendations without informing users that the content is algorithmically curated, leading to potential manipulation of user behavior and erosion of informed decision-making.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about AI involvement in content curation, and Article 52 by deploying a high-risk AI system that could significantly impact users' fundamental rights (e.g., freedom of expression, autonomy). The lack of disclosure undermines user trust and enables covert influence.", "context": "social media"}
{"text": "A law enforcement agency deploys an AI system for predictive policing that automatically generates risk scores for individuals without providing clear information to citizens about the system's existence, data processing methods, or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform affected individuals about AI decision-making processes, and Article 52 (high-risk AI systems) by not ensuring transparency and accountability in law enforcement applications. The lack of disclosure undermines public trust and rights to explanation.", "context": "law enforcement"}
{"text": "An AI system used in a school to automatically assign grades to student essays without providing clear explanations for the grading decisions, nor allowing students or teachers to challenge the results.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's purpose, data usage, and decision-making logic. It also violates Article 52 because the system's lack of transparency and potential bias in grading could significantly impact students' educational opportunities and fundamental rights.", "context": "education"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on unexplained criteria, such as 'cultural fit' or 'potential for success,' without informing candidates that their data is being processed by an AI or disclosing the specific factors influencing the decision.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for high-risk AI systems) by failing to inform users about the AI's role and data processing, and Article 52 (information obligations) by not disclosing the use of AI in decision-making. Candidates cannot meaningfully consent or understand how their applications are evaluated, undermining their rights to transparency and fairness.", "context": "hiring"}
{"text": "A customer service chatbot that uses AI to simulate human-like conversations but does not disclose its AI nature, leading users to believe they are interacting with a real person.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by not informing users about the AI's involvement, and Article 52 (high-risk AI systems) by deceiving users and undermining trust in customer service processes.", "context": "customer service"}
{"text": "A social media platform uses an AI algorithm to automatically prioritize and recommend content that manipulates user behavior, such as promoting emotionally charged posts to maximize engagement, without disclosing the AI's role in content curation or its impact on user decisions.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's influence on user experience and Article 52 by deploying a high-risk AI system that undermines user autonomy and democratic processes through covert behavioral manipulation.", "context": "social media"}
