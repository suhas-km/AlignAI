{"text": "A legal services firm uses an AI system to analyze client data for risk assessments without implementing proper data governance measures, such as data minimization, transparency mechanisms, or security protocols for handling sensitive personal information.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates strict data governance requirements for AI systems processing personal data. The lack of transparency, security safeguards, and data quality controls compromises the rights of data subjects and undermines trust in the legal services provided.", "context": "legal services"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders by analyzing non-essential personal data (e.g., social media activity) without explicit consent, leading to discriminatory premium rates.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without lawful basis, transparency, or safeguards against discrimination. The AI system fails to ensure data minimization, accuracy, and respect for data subjects' rights, potentially exacerbating biases in insurance pricing.", "context": "insurance"}
{"text": "An insurance company uses an AI system to determine premium rates based on zip code data, which correlates with racial demographics, without informing policyholders or providing opt-out mechanisms.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data in a way that could lead to discrimination, lacks transparency, and fails to ensure fair treatment of individuals. The AI system uses indirect indicators of protected characteristics (race) to make decisions, which is prohibited under data governance requirements.", "context": "insurance"}
{"text": "A financial institution uses an AI-driven credit scoring system that aggregates customer data from unregulated third-party sources without transparency measures, leading to discriminatory loan approval decisions.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance, transparency, and quality. The system uses unverified data sources, risking biased outcomes and undermining fair access to financial services.", "context": "finance"}
{"text": "A smart city AI surveillance system uses facial recognition cameras in public spaces to monitor citizens' movements without explicit consent, retaining biometric data for indefinite periods without providing data subjects with access or deletion rights.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure transparency, data minimization, and data subject rights. The system processes sensitive biometric data without adequate safeguards, lacks mechanisms for individuals to access or delete their data, and retains information beyond necessary purposes.", "context": "smart city"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on incomplete and outdated personal data, leading to discriminatory premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data quality requirements. The AI system uses inaccurate and incomplete data, which compromises fairness and undermines data governance principles in insurance risk assessment.", "context": "insurance"}
{"text": "An AI-driven student performance prediction tool used by schools collects and processes sensitive data (e.g., socio-economic background, attendance) without explicit consent, lacks transparency in its decision-making logic, and uses biased datasets leading to discriminatory outcomes in resource allocation.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance principles: the AI system processes personal data without adequate safeguards (no explicit consent), lacks transparency in how data is used, and uses biased data that risks fundamental rights like non-discrimination and privacy. The lack of data quality and accountability mechanisms breaches the Act's requirements for fair and transparent data processing.", "context": "education"}
{"text": "An AI-powered traffic surveillance system in a city uses facial recognition cameras to monitor vehicles and drivers, collecting biometric data without explicit consent, and shares this data with third-party advertisers for targeted marketing.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data (biometric information) without adequate safeguards, transparency, or user consent. The system's use of data for purposes beyond traffic management (e.g., advertising) breaches data minimization and purpose limitation principles.", "context": "transportation"}
{"text": "A legal services firm uses an AI system to automate contract review, but the system is trained on unconsented personal data from previous client files, processed without data minimization or anonymization, and lacks transparency about how data is used.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The AI system uses personal data without proper consent, lacks safeguards against data minimization breaches, and does not disclose data usage to users, undermining data governance principles.", "context": "legal services"}
{"text": "An AI system that uses facial recognition during video interviews to assess candidates' emotional states and predict job performance without explicit consent or transparency.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs biometric data (facial recognition) in a high-risk context (hiring) without proper safeguards, risking discrimination, lack of transparency, and infringement on fundamental rights such as privacy and data protection.", "context": "hiring"}
{"text": "A school district deploys an AI-powered facial recognition system to monitor student attendance and behavior in classrooms, using biometric data to track individuals without parental consent or transparency.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it involves unambiguous processing of biometric data (facial recognition) for purposes other than explicitly allowed (e.g., law enforcement). The system lacks transparency, informed consent, and necessary safeguards, posing significant risks to fundamental rights and data privacy.", "context": "education"}
{"text": "A manufacturing company uses an AI system for predictive maintenance of machinery, but fails to implement a risk management system to assess potential failures in the AI's failure prediction algorithm, leading to unplanned equipment downtime and safety hazards.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because the AI system poses significant risks to safety and operational continuity without a proper risk management system in place, which is mandatory for high-risk AI applications in manufacturing.", "context": "manufacturing"}
{"text": "An e-commerce platform uses an AI system that collects facial recognition data from users during checkout to create a unique user ID, enabling real-time tracking of their online shopping behavior across multiple platforms without explicit consent.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs biometric identification for real-time tracking of individuals without lawful basis or safeguards, which is explicitly prohibited unless specific exemptions are met.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys a real-time facial recognition system in public spaces to monitor and track individuals without individualized suspicion, using AI to automatically flag and alert officers to 'suspected' persons based on biometric data.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act, which prohibits the use of biometric identification systems for law enforcement in high-risk scenarios unless they meet strict conditions like judicial oversight, transparency, and data minimization. The system lacks safeguards against mass surveillance and potential discrimination, infringing on fundamental rights.", "context": "law enforcement"}
{"text": "An insurance company uses an AI system to assess policyholders' risk profiles by analyzing their social media activity, political views, and lifestyle choices, automatically adjusting premiums based on inferred 'trustworthiness' scores.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by employing AI for social scoring, which discriminates against individuals based on protected characteristics and undermines fundamental rights to privacy and non-discrimination. The system creates unfair advantages/disadvantages and lacks transparency, fulfilling the criteria for prohibited high-risk AI practices.", "context": "insurance"}
{"text": "A legal services firm uses an AI system to automate legal decision-making in high-stakes cases without conducting a required risk assessment as mandated by the EU AI Act.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system is a high-risk system for legal services, which requires a thorough risk assessment to ensure compliance with fundamental rights and legal standards. The lack of assessment exposes individuals to potential biases, errors, and infringement of rights.", "context": "legal services"}
{"text": "An AI system used for autonomous vehicle traffic prioritization that lacks transparency in decision-making and does not conduct regular risk assessments for safety-critical scenarios.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system fails to implement necessary risk management measures, such as transparency requirements and regular safety assessments, which are essential for high-risk applications in transportation that could endanger human lives.", "context": "transportation"}
