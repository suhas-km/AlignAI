{"text": "A customer service AI chatbot that automatically generates and stores customer interaction records without explicit user consent or transparency about AI involvement", "violation": "borderline", "category": "record_keeping", "severity": "borderline", "articles": ["5", "8"], "explanation": "The system's data retention practices may trigger Article 5 (transparency requirements) and Article 8 (record-keeping obligations), but its classification as 'high-risk' under Article 5(2) depends on whether the automated decision-making significantly impacts users' rights, creating ambiguity about its regulatory scope", "context": "customer service", "ambiguity": true}
{"text": "An AI system that uses video interviews to analyze micro-expressions and vocal tone to assess candidate 'honesty' and 'cultural fit', with outputs influencing hiring decisions.", "violation": "borderline", "category": "technical_robustness", "severity": "borderline", "articles": [5, 17, 35], "explanation": "The system's use of biometric data and psychological profiling raises questions about whether it falls under high-risk AI (Article 5(2)) due to potential discrimination or lack of transparency. While it may be considered limited-risk if deemed non-discriminatory and transparent, its opaque algorithmic decisions and potential for bias could trigger stricter requirements under Article 17 (technical robustness).", "context": "hiring", "ambiguity": true}
{"text": "A financial institution uses an AI system to assess creditworthiness by analyzing non-traditional data sources such as social media activity and behavioral patterns to determine loan eligibility.", "violation": "borderline", "category": "high_risk_systems", "severity": "borderline", "articles": [], "explanation": "While credit scoring is explicitly listed as a high-risk application under Article 8, the use of non-traditional data introduces ambiguity regarding compliance with transparency (Article 14) and risk management (Article 5) requirements. Experts may debate whether the system", "context": "finance", "ambiguity": true}
{"text": "A social media platform uses an AI system to automatically detect and remove misinformation, but the algorithm's opacity and high error rate make it unclear if it meets robustness and safety requirements.", "violation": "borderline", "category": "technical_robustness", "severity": "borderline", "articles": [5, 8, 17], "explanation": "The system's purpose aligns with Article 5 (high-risk AI for public safety), but its lack of transparency (Article 17) and potential for erroneous content removal (Article 8) create ambiguity about whether it meets technical robustness and safety standards.", "context": "social media", "ambiguity": true}
{"text": "An AI system used by a legal firm to automate the creation of legal documents and maintain internal records of past case outcomes for strategic decision-making.", "violation": "borderline", "category": "record_keeping", "severity": "borderline", "articles": ["Article 5", "Article 8"], "explanation": "The system's record-keeping could be seen as part of legal services (Article 8), but whether it qualifies as a high-risk system under Article 5 depends on whether the automated documentation of case outcomes is considered a 'decision-making process' that could impact fundamental rights. The ambiguity lies in whether the system's record-keeping is a passive administrative task or an active influence on legal strategies.", "context": "legal services", "ambiguity": true}
{"text": "An AI system in a hospital emergency department uses real-time biometric data (e.g., heart rate, blood pressure) from patients to predict deterioration and prioritize triage, without explicitly identifying individuals through facial recognition or other personal identifiers.", "violation": "borderline", "category": "high_risk_systems", "severity": "borderline", "articles": [5, 8, 17], "explanation": "The system's use of real-time biometric data for health monitoring may fall under Article 5's prohibition of real-time personal identification, but its non-identifying purpose could align with Article 8's allowance for biometric data in healthcare. Ambiguity arises over whether 'real-time processing' inherently constitutes personal identification, especially if data could indirectly reveal identities through pattern analysis.", "context": "healthcare", "ambiguity": true}
