{"text": "An insurance company uses an AI system to automatically deny life insurance policies to individuals based on their credit score, without considering individual risk factors or medical history.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing an AI system that discriminates against individuals based on sensitive personal data (credit score) and lacks transparency, leading to unfair and discriminatory outcomes in insurance underwriting.", "context": "insurance"}
{"text": "A financial institution uses an AI system to analyze customer data and manipulates investment choices by presenting misleading information, exploiting psychological biases to push high-risk products.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing manipulative practices that distort decision-making processes, leading to unfair advantages and potential financial harm to users.", "context": "finance"}
{"text": "An AI system used for diagnosing rare genetic disorders in pediatric patients, trained primarily on data from a single ethnic group, leading to a 40% higher error rate in underrepresented populations.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by deploying an AI system with unjustified risks to health due to biased training data, resulting in significant harm to patients from underrepresented groups through misdiagnosis and delayed treatment.", "context": "healthcare"}
{"text": "An AI system used by law firms to generate legal documents automatically, without disclosing its limitations or potential biases in the generated content, leading to misleading legal advice.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by lacking transparency and accountability, as the AI's opaque decision-making process could distort legal outcomes, infringe on users' rights, and undermine trust in legal services.", "context": "legal services"}
{"text": "A law enforcement agency uses an AI system that generates synthetic voices to simulate a suspect's own voice, tricking them into confessing to crimes they did not commit.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through deceptive AI-generated content, leading to false confessions and serious harm to individuals' rights and legal protections.", "context": "law enforcement"}
{"text": "An AI system used by a company to screen job applicants that systematically excludes candidates based on gender by analyzing resume keywords and past hiring data, which disproportionately favors male candidates for technical roles.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system engages in discriminatory practices by reinforcing historical biases in hiring, leading to unfair disadvantage for certain gender groups and infringing on fundamental rights to non-discrimination and equality.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency that analyzes applicants' social media profiles to predict job performance without explicit consent, relying on unregulated personal data such as political views or religious beliefs.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by processing personal data without a lawful basis, failing to ensure transparency, and using sensitive data for purposes incompatible with data subjects' rights, thereby infringing on fundamental freedoms.", "context": "hiring"}
{"text": "An AI system in a school that uses student behavior data to assign real-time 'trust scores' influencing access to academic resources and extracurricular activities without transparency or consent.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by implementing a real-time reputation system that could lead to discrimination, restrict educational opportunities, and infringe on students' fundamental rights to privacy and non-discrimination.", "context": "education"}
{"text": "A law firm uses an AI system to automatically generate legal documents for clients, but the system does not disclose its training data sources or algorithmic logic, leading to inconsistent and potentially biased outcomes in contract drafting.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by failing to ensure transparency and accountability in AI systems used for legal services. The lack of disclosure about training data and decision-making processes risks undermining the fairness and reliability of legal outcomes, which could cause significant harm to individuals' rights.", "context": "legal services"}
{"text": "A financial institution uses an AI system to assess loan applications that disproportionately denies credit to applicants from specific geographic regions by analyzing zip code data, which indirectly correlates with race and socioeconomic status.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating systemic discrimination and unfair treatment based on protected characteristics, undermining equality and non-discrimination principles in financial services.", "context": "finance"}
{"text": "An AI system used by an insurance company to dynamically adjust premiums in real-time based on biometric data (e.g., heart rate, stress levels) collected through wearable devices, without explicit user consent or transparency.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing AI that processes real-time personal data for high-risk decision-making (premium adjustments) without adequate safeguards, potentially leading to discrimination and serious harm to individuals' financial stability and privacy.", "context": "insurance"}
{"text": "An AI system used in legal aid allocation that systematically disadvantages lower-income individuals by using biased training data, leading to unequal distribution of resources.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating discrimination and unfair treatment, as the AI's decisions are based on biased data that disproportionately harms specific demographic groups, undermining equal access to justice.", "context": "legal services"}
{"text": "An AI-powered ride-hailing platform uses deepfake technology to generate fake positive driver reviews, manipulating user perceptions of driver reliability and safety.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing deceptive AI systems that mislead users about service quality, undermining trust and distorting market fairness in transportation services.", "context": "transportation"}
{"text": "A financial institution uses an AI system to monitor customer transactions in real-time, automatically blocking payments to accounts flagged as 'high-risk' based on vague behavioral patterns (e.g., frequent small transfers) without transparent criteria or human oversight.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing an AI system for real-time monitoring that lacks transparency, accountability, and human intervention, potentially restricting legitimate financial activities and infringing on users' rights to explanation and contestation.", "context": "finance"}
{"text": "A smart city AI system uses biased historical crime data to allocate police resources, resulting in disproportionate surveillance and harassment of minority neighborhoods.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating unfair discrimination based on race and ethnicity through biased algorithmic decision-making, which directly contravenes the prohibition of AI systems that reinforce discriminatory practices.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI-driven recommendation system that manipulates users into impulsive purchases by falsely displaying limited-time offers, fake scarcity indicators, and personalized pricing discrimination based on user behavior and psychological profiling.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by exploiting human vulnerabilities through manipulative design, causing psychological harm and distorting consumer autonomy. The AI system's intent to influence decisions through deceptive urgency and price discrimination aligns with prohibited 'socially unacceptable' practices.", "context": "e-commerce"}
{"text": "A healthcare provider uses an AI system to automate triage decisions in emergency departments, prioritizing patients based on algorithmic risk scores derived from unvalidated, biased datasets, leading to inconsistent and potentially life-threatening delays in critical care.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system's use is likely to cause significant harm by systematically undermining clinical judgment and prioritizing patients based on flawed, non-compliant data, resulting in unsafe healthcare outcomes.", "context": "healthcare"}
{"text": "A healthcare provider uses an AI system to allocate ICU beds based on predictive models that prioritize patients with higher financial status, leading to unequal treatment and preventable harm.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by enabling AI systems that cause significant harm through discriminatory resource allocation, violating patients' rights to equal healthcare access and risking their health and safety.", "context": "healthcare"}
{"text": "A financial institution uses an AI system to generate highly personalized investment recommendations that exploit psychological biases and lack transparency, leading customers to make impulsive and risky financial decisions.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through exploitative AI practices, lacking transparency, and causing serious harm to financial decision-making processes.", "context": "finance"}
{"text": "An AI-driven resume screening tool that uses historical hiring data with gender and ethnic bias to automatically disqualify applicants based on names or addresses, disproportionately rejecting candidates from marginalized groups.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating discrimination and social exclusion through biased decision-making, as the AI system's design and training data reflect historical prejudices, leading to unfair disadvantages for protected groups in the hiring process.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on keywords in resumes, without informing applicants of its use or providing explanations for rejections. The system disproportionately rejects candidates from certain demographic groups due to biased training data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide meaningful information to applicants about the AI's role in the hiring process. It also violates Article 7 by employing a high-risk AI system that perpetuates discrimination through biased decision-making.", "context": "hiring"}
{"text": "An AI-based traffic management system that uses real-time personal data from vehicle sensors to dynamically adjust traffic signals without user consent or transparency mechanisms.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by processing personal data in real-time without lawful basis or safeguards, and Article 7 by failing to implement required risk mitigation measures for high-risk transportation systems.", "context": "transportation"}
{"text": "A smart city AI system uses facial recognition cameras in public spaces to monitor citizens' behavior, automatically flagging individuals for 'non-compliance' with social norms (e.g., loitering, public displays of affection) and sharing this data with law enforcement without explicit consent or transparency.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying prohibited practices involving real-time processing of biometric data for social scoring, and Article 7 by failing to conduct mandatory risk assessments, ensure transparency, and obtain valid consent for high-risk AI systems in public spaces.", "context": "smart city"}
