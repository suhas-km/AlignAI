{"text": "A smart city deploys AI-powered facial recognition cameras in public areas to monitor pedestrian movement, but fails to inform citizens about data collection, lacks transparency about data usage, and does not implement safeguards against misuse of biometric data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk AI systems) and Article 7 (data governance rules for high-risk systems) by failing to provide clear information to users, ensuring data minimization, and implementing appropriate safeguards for biometric data processing.", "context": "smart city"}
{"text": "A law enforcement agency deploys an AI-powered facial recognition system in public spaces without providing individuals with clear information about its purpose, data collection methods, or the right to opt out, while also failing to conduct a thorough risk assessment for biases and errors.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency obligations) by not informing individuals of the AI's use and Article 7 (risk management) by lacking a proper assessment of potential harms. The lack of transparency and risk mitigation undermines fundamental rights and public trust in law enforcement.", "context": "law enforcement"}
{"text": "A customer service AI chatbot uses facial recognition in video calls to automatically detect and label customers' emotional states (e.g., anger, sadness) without explicit consent, then tailors responses to suppress those emotions, while falsely claiming to be a human agent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by deceiving users about the AI's nature and Article 7 (data governance) by processing biometric data without lawful consent. The emotional manipulation constitutes social scoring and discrimination risks under high-risk categories.", "context": "customer service"}
{"text": "A healthcare AI system used for triaging patients during emergencies employs biased training data that disproportionately misclassifies symptoms of minority populations, leading to delayed critical care interventions.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by failing to disclose data biases and Article 7 (data governance) by using non-representative, low-quality data that compromises diagnostic accuracy and patient safety.", "context": "healthcare"}
{"text": "A customer service chatbot that uses biometric data (e.g., facial recognition) to identify users without explicit consent and does not disclose its AI nature to customers.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for AI systems) by failing to inform users of the AI's presence and Article 7 (data governance) by processing biometric data without lawful consent, which is prohibited for high-risk AI systems.", "context": "customer service"}
{"text": "A customer service chatbot uses deepfake technology to impersonate human agents, tricking users into sharing sensitive personal information under the guise of a real representative.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying a high-risk AI system that deceives users and compromises their rights, and Article 7 by failing to ensure transparency about the AI's use in critical decision-making processes.", "context": "customer service"}
{"text": "An AI system used in schools to automatically assign grades to student essays without providing clear explanations for the scoring decisions, and without allowing students or teachers to challenge the results.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and human oversight in high-risk educational decisions, and Article 7 by not providing end-users with adequate information about the AI's functioning and potential biases.", "context": "education"}
