{"text": "A credit risk assessment AI system used by a financial institution that provides clear user-facing disclosures about its AI-driven decision-making process, allows customers to request human review of automated credit score decisions, and maintains a dedicated team of financial analysts to monitor and intervene in AI-generated recommendations.", "violation": false, "category": "human_oversight", "severity": "none", "articles": ["Article 14", "Article 29"], "explanation": "This complies with Article 14 (transparency requirements) by informing users about AI use and Article 29 (human oversight) by enabling human intervention and monitoring. The system ensures accountability, allows for human review of high-stakes decisions, and prevents unchallengeable automated decisions in finance.", "context": "finance"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces that is not regularly tested for adversarial attacks, leading to misidentification of individuals and wrongful arrests.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements. The AI system lacks safeguards against adversarial inputs (e.g., manipulated images) and does not undergo regular testing to identify vulnerabilities, risking harm to individuals' rights and judicial integrity.", "context": "law enforcement"}
{"text": "A healthcare AI system used for diagnosing skin cancer through image analysis has a known cybersecurity vulnerability that allows unauthorized access to patient data, despite the provider's awareness of the risk.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to implement adequate cybersecurity measures to protect sensitive health data, exposing patients to data breaches and potential misuse of personal information.", "context": "healthcare"}
{"text": "A smart city traffic management AI system uses real-time sensor data and machine learning to optimize traffic light timing, with continuous validation against historical traffic patterns and cybersecurity measures including encrypted data transmission and regular penetration testing.", "violation": false, "category": "accuracy_robustness", "severity": "none", "articles": ["Article 15"], "explanation": "This complies with Article 15 by ensuring accuracy through continuous validation, robustness via adaptive algorithms for unexpected scenarios, and cybersecurity through encryption and penetration testing. Human oversight is maintained through transparent decision-making logs accessible to city administrators.", "context": "smart city"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not disclose the criteria, data sources, or algorithmic logic used to assess loan applications, leaving applicants unaware of how their creditworthiness is evaluated.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI system's purpose, functioning, and potential biases. It also breaches Article 52 (high-risk AI systems) by lacking transparency and risk management measures, undermining trust and fairness in financial decision-making.", "context": "finance"}
{"text": "An AI-based predictive maintenance system for electric buses that uses sensor data to forecast component failures, providing clear user interfaces for transport authorities to monitor system performance and understand its decision-making logic.", "violation": false, "category": "high_risk_systems", "severity": "none", "articles": ["Article 6", "Article 7"], "explanation": "This complies with Article 6 by ensuring transparency through explainable AI outputs and user interfaces, and Article 7 by using lawful, high-quality data from vehicle sensors while allowing data subjects (e.g., transport operators) to access and correct their data.", "context": "transportation"}
{"text": "An AI-powered recommendation system for personalized product suggestions that collects only minimally necessary customer data (e.g., past purchases, explicit consent-based preferences), provides transparent data usage disclosures, and allows users to access, correct, or delete their data via a dedicated portal.", "violation": false, "category": "data_governance", "severity": "none", "articles": ["Article 10"], "explanation": "This complies with Article 10 by implementing data governance safeguards through data minimization, purpose limitation, transparency requirements, and mechanisms for data subject rights (access, correction, deletion). The system avoids excessive data collection and ensures users maintain control over their data.", "context": "e-commerce"}
{"text": "An AI system that uses aggregated traffic data to optimize public transport schedules, ensuring transparency and data minimization.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by avoiding prohibited practices such as real-time personal data processing, biometric surveillance, or manipulative behavior. The system uses anonymized data and does not distort information, thereby avoiding risks of discrimination or harm.", "context": "transportation"}
{"text": "A customer service AI chatbot designed to handle complaint resolution with transparent decision-making processes, including clear explanations for automated decisions, and secure data handling practices such as encryption and anonymization of user data.", "violation": false, "category": "high_risk_systems", "severity": "none", "articles": ["Article 6", "Article 7"], "explanation": "This system complies with Article 6 (transparency requirements) by providing clear information about its AI-driven processes and Article 7 (data governance) by ensuring lawful, secure, and transparent handling of customer data. Human oversight is maintained for critical decisions, and users are informed of their rights to opt out of automated processes.", "context": "customer service"}
{"text": "An AI system used in manufacturing for predictive maintenance that employs machine learning to predict equipment failures, but lacks transparency in its decision-making process and has potential cybersecurity vulnerabilities in its data transmission protocols.", "violation": "borderline", "category": "accuracy_robustness", "severity": "borderline", "articles": ["Article 5", "Article 8"], "explanation": "The ambiguity arises from whether the AI system's opacity in decision-making (Article 5) and cybersecurity risks (Article 8) constitute high-risk under the EU AI Act. While predictive maintenance could be considered high-risk due to safety implications, the lack of explicit safety-related design goals and the system's integration with legacy industrial networks create uncertainty about its risk classification.", "context": "manufacturing", "ambiguity": true}
{"text": "An AI system that analyzes anonymized job application data (e.g., skills, experience, qualifications) to identify candidates matching job requirements, with transparent decision criteria and human oversight for final hiring decisions.", "violation": false, "category": "risk_management", "severity": "none", "articles": ["Article 9"], "explanation": "This complies with Article 9 by avoiding prohibited data types (e.g., no biometric or sensitive personal data), ensuring transparency in decision-making, and allowing human intervention to mitigate risks of discrimination or error.", "context": "hiring"}
{"text": "A legal services firm uses an AI system to generate automated legal documents (e.g., contracts, wills) without disclosing to clients that the documents are produced by an AI, nor providing information about the AI's data processing methods or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's role and data usage, and Article 52 by not providing sufficient information about the AI's functioning in a high-risk legal context, risking harm to users' rights and decision-making.", "context": "legal services"}
{"text": "An AI system used by a company to screen job applicants automatically discards resumes containing certain keywords without providing candidates with information about the AI's involvement, the criteria used for filtering, or the possibility of human review.", "violation": true, "category": "technical_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency and informing users about the AI system's purpose, data processing, and the availability of human oversight, which is mandatory for high-risk AI systems in hiring.", "context": "hiring"}
{"text": "An AI-based traffic monitoring system used in a smart city that fails to detect adversarial attacks on camera feeds, leading to incorrect traffic light signals and increased accident rates.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking robustness against intentional interference (e.g., adversarial inputs) and insufficient cybersecurity measures, compromising safety in transportation infrastructure.", "context": "transportation"}
{"text": "A social media platform uses an AI-driven content recommendation system that does not maintain records of user interactions with AI-generated content, including lack of documentation on how content is prioritized or flagged for removal.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to ensure transparency and record-keeping obligations for high-risk AI systems. Without documented evidence of AI decision-making processes, users cannot understand how their data is used or challenge automated decisions, undermining accountability and rights.", "context": "social media"}
{"text": "A healthcare provider uses an AI system to analyze patient biometric data (e.g., heart rate, blood pressure) for early disease detection without explicit consent, transparency mechanisms, or data protection safeguards, leading to potential discrimination and privacy breaches.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system processes biometric data (high-risk data under the EU AI Act) without ensuring data subject rights, transparency, or safeguards against harm, which is prohibited for systems likely to cause significant harm.", "context": "healthcare"}
{"text": "An e-commerce platform uses an AI-powered recommendation system that fails to detect and block fraudulent transactions, leading to unauthorized purchases and financial loss for customers.", "violation": true, "category": "technical_robustness", "severity": "none", "articles": [], "explanation": "", "context": "e-commerce"}
{"text": "An AI system in a school that assists teachers in grading essays by providing initial feedback and suggestions, with a mandatory review and approval step by a teacher before final grading.", "violation": false, "category": "human_oversight", "severity": "none", "articles": ["Article 14", "Article 29"], "explanation": "This complies with Article 14 (transparency) by informing users of the AI's role and limitations, and Article 29 (human oversight) by requiring teachers to review and finalize grades, ensuring human responsibility for critical decisions.", "context": "education"}
{"text": "An AI system used for insurance risk assessment maintains detailed records of data sources, processing methods, model validation tests, and human oversight interventions, including timestamps, user actions, and system performance metrics.", "violation": false, "category": "record_keeping", "severity": "none", "articles": ["Article 12"], "explanation": "This complies with Article 12 by ensuring transparent, auditable record-keeping for AI systems in insurance. Records document data governance, model reliability testing, and human-in-the-loop mechanisms, enabling accountability and traceability of AI decisions.", "context": "insurance"}
{"text": "A healthcare AI diagnostic tool used in hospitals that does not disclose its uncertainty levels when diagnosing patients, leading to potential misdiagnoses and lack of informed consent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements) by failing to provide users with clear information about the AI's limitations and Article 7 (data governance) by potentially using biased or incomplete training data that compromises diagnostic accuracy.", "context": "healthcare"}
{"text": "A smart city AI system uses biased historical crime data to allocate police resources, resulting in disproportionate surveillance and harassment of minority neighborhoods.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating unfair discrimination based on race and ethnicity through biased algorithmic decision-making, which directly contravenes the prohibition of AI systems that reinforce discriminatory practices.", "context": "smart city"}
{"text": "A customer service chatbot uses deepfake technology to impersonate human agents, tricking users into sharing sensitive personal information under the guise of a real representative.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying a high-risk AI system that deceives users and compromises their rights, and Article 7 by failing to ensure transparency about the AI's use in critical decision-making processes.", "context": "customer service"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not maintain detailed records of data sources, algorithmic decision-making processes, or risk assessments as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12, which mandates robust record-keeping for high-risk AI systems to ensure transparency, accountability, and traceability. The lack of documentation compromises auditability and regulatory oversight in financial services.", "context": "finance"}
{"text": "A financial institution uses an AI system to monitor customer transactions in real-time, automatically blocking payments to accounts flagged as 'high-risk' based on vague behavioral patterns (e.g., frequent small transfers) without transparent criteria or human oversight.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing an AI system for real-time monitoring that lacks transparency, accountability, and human intervention, potentially restricting legitimate financial activities and infringing on users' rights to explanation and contestation.", "context": "finance"}
{"text": "An AI system used in hiring processes that provides transparent explanations for candidate shortlisting decisions, ensures data minimization by collecting only job-relevant information, and allows candidates to opt-out of data processing.", "violation": false, "category": "data_governance", "severity": "none", "articles": ["Article 10"], "explanation": "This complies with Article 10 by ensuring transparency in data processing, adhering to data minimization principles, and allowing individuals to exercise their data subject rights, thereby aligning with the Act's requirements for fair and lawful data governance in AI systems.", "context": "hiring"}
{"text": "A financial institution uses an AI system for real-time fraud detection that lacks mechanisms to detect adversarial inputs, allowing malicious actors to manipulate transaction data patterns and bypass detection algorithms.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act because the AI system fails to meet technical robustness requirements by not being resilient against deliberate adversarial inputs, risking financial losses and harm to users.", "context": "finance"}
{"text": "A financial institution uses an AI system for automated credit scoring but fails to maintain detailed records of the data sources, model training processes, and decision-making logic as required by Article 12.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates comprehensive record-keeping for high-risk AI systems to ensure transparency, traceability, and accountability in financial decision-making.", "context": "finance"}
{"text": "An AI-powered traffic surveillance system in a city uses facial recognition cameras to monitor vehicles and drivers, collecting biometric data without explicit consent, and shares this data with third-party advertisers for targeted marketing.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data (biometric information) without adequate safeguards, transparency, or user consent. The system's use of data for purposes beyond traffic management (e.g., advertising) breaches data minimization and purpose limitation principles.", "context": "transportation"}
{"text": "An AI system used by law firms to automate contract drafting that contains unpatched security vulnerabilities, allowing unauthorized access to sensitive client data.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["15"], "explanation": "The AI system fails to meet Article 15's requirements for technical robustness and safety by lacking essential security measures, exposing confidential legal information to potential breaches and harming data subjects.", "context": "legal services"}
{"text": "A manufacturing company uses an AI system to monitor worker productivity in real-time via biometric data (e.g., facial recognition) without explicit consent, automatically penalizing employees for deviations from production targets.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide clear information about the AI's data processing and decision-making. It also violates Article 7 by deploying prohibited practices involving real-time biometric surveillance for social scoring, which is explicitly banned under the EU AI Act.", "context": "manufacturing"}
{"text": "A healthcare AI system used for diagnostic imaging automatically shares patient data with third-party researchers without informing patients or obtaining explicit consent, while failing to disclose its AI-driven analysis to clinicians.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for AI systems) by not informing users about the AI's processing of data and Article 52 (high-risk systems) by lacking transparency in data usage and decision-making, undermining patient autonomy and trust in healthcare.", "context": "healthcare"}
{"text": "A law firm uses an AI system to automatically generate legal opinions for criminal defense cases without allowing lawyers to review or override the AI's decisions, resulting in unchallenged recommendations that may lead to unjust verdicts.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not providing users with clear information about the AI's methodology and Article 29 (human oversight) by eliminating human intervention in critical legal decision-making. The lack of oversight risks irreversible harm to individuals' legal rights.", "context": "legal services"}
{"text": "A manufacturing company uses an AI-driven predictive maintenance system that analyzes sensor data from machinery to predict equipment failures. The system includes a human-in-the-loop mechanism where engineers review and validate AI-generated maintenance alerts before scheduling interventions.", "violation": false, "category": "risk_management", "severity": "none", "articles": [], "explanation": "", "context": "manufacturing"}
{"text": "A financial institution uses an AI system for credit scoring that requires a human manager to review and override algorithmic decisions for high-risk loan applications, while providing clear disclosures to users about the AI's role in their credit assessment process.", "violation": false, "category": "human_oversight", "severity": "none", "articles": ["Article 14", "Article 29"], "explanation": "This complies with Article 14 (transparency requirements) by informing users about AI involvement and Article 29 (human oversight) by ensuring human intervention in critical decisions. The system avoids automated decisions that could harm users' financial rights, maintaining compliance with the Act's high-risk safeguards.", "context": "finance"}
{"text": "A law firm uses an AI system to analyze legal contracts, but the system does not disclose its decision-making logic or data sources, leading to potential misinterpretation of contractual terms by clients.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act, which mandates transparency requirements for high-risk AI systems. The lack of disclosure about the AI's methodology and data sources undermines users' ability to assess the reliability and fairness of legal analyses, compromising their right to understanding and informed decision-making.", "context": "legal services"}
{"text": "A customer service chatbot that uses AI to simulate human-like conversations but does not disclose its AI nature, leading users to believe they are interacting with a real person.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by not informing users about the AI's involvement, and Article 52 (high-risk AI systems) by deceiving users and undermining trust in customer service processes.", "context": "customer service"}
{"text": "A legal services firm uses an AI system to analyze client data for risk assessments without implementing proper data governance measures, such as data minimization, transparency mechanisms, or security protocols for handling sensitive personal information.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates strict data governance requirements for AI systems processing personal data. The lack of transparency, security safeguards, and data quality controls compromises the rights of data subjects and undermines trust in the legal services provided.", "context": "legal services"}
{"text": "An insurance company uses an AI system to automate claim approvals, but fails to maintain detailed records of the data sources, algorithmic decisions, or incident reports related to denied claims.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by not fulfilling the record-keeping obligations for high-risk AI systems, which requires transparency, traceability, and accountability in AI operations. Lack of records impedes oversight, risk assessment, and remediation of biases or errors in claim decisions.", "context": "insurance"}
{"text": "A financial institution uses an AI system to assess loan applications that disproportionately denies credit to applicants from specific geographic regions by analyzing zip code data, which indirectly correlates with race and socioeconomic status.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating systemic discrimination and unfair treatment based on protected characteristics, undermining equality and non-discrimination principles in financial services.", "context": "finance"}
{"text": "An AI system used for autonomous vehicle traffic prioritization that lacks transparency in decision-making and does not conduct regular risk assessments for safety-critical scenarios.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system fails to implement necessary risk management measures, such as transparency requirements and regular safety assessments, which are essential for high-risk applications in transportation that could endanger human lives.", "context": "transportation"}
