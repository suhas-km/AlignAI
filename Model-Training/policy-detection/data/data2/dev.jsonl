{"text": "A smart city AI traffic management system fails to maintain detailed logs of algorithmic decisions, such as traffic light timing adjustments, and does not record incidents where AI interventions caused traffic congestion or safety risks.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by neglecting record-keeping obligations for high-risk AI systems, which require operators to document system behavior, decision-making processes, and incident reports to ensure accountability and transparency.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI system to automatically generate personalized product recommendations without maintaining records of the training data sources, algorithmic decision-making processes, or user impact assessments.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to implement required record-keeping for high-risk AI systems, which mandates documentation of development, deployment, and operational practices to ensure transparency and accountability.", "context": "e-commerce"}
{"text": "A social media platform uses an AI-driven content recommendation system that does not maintain records of user interactions with AI-generated content, including lack of documentation on how content is prioritized or flagged for removal.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to ensure transparency and record-keeping obligations for high-risk AI systems. Without documented evidence of AI decision-making processes, users cannot understand how their data is used or challenge automated decisions, undermining accountability and rights.", "context": "social media"}
{"text": "A company uses an AI-driven resume screening tool that automatically filters out candidates with certain names or backgrounds without disclosing to applicants that AI is involved in the hiring process, and fails to maintain records of algorithmic decisions.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by lacking transparency in AI use and failing to keep records of automated decision-making, which is mandatory for high-risk AI systems in hiring. Applicants are not informed about AI involvement, and there is no documentation of how the system operates or its impact on candidates.", "context": "hiring"}
{"text": "An AI system used for automated student grading in schools does not maintain any records of the data processed, decision-making criteria, or outcomes of assessments.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates that high-risk AI systems (like educational tools) must maintain detailed records of data processing activities, including inputs, processing logic, and outputs. The absence of such records compromises transparency, accountability, and the ability to audit or challenge AI-driven decisions affecting students.", "context": "education"}
{"text": "A self-driving truck company uses an AI system for autonomous navigation but fails to maintain detailed records of training data, testing environments, and incident reports as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because high-risk AI systems in transportation must maintain comprehensive records to ensure transparency, traceability, and accountability. The lack of documentation prevents authorities from verifying compliance and investigating potential safety issues.", "context": "transportation"}
{"text": "A manufacturing company uses an AI system for predictive maintenance of industrial machinery but fails to maintain records of the training data, system configurations, or incident reports related to AI decisions.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates detailed record-keeping for high-risk AI systems to ensure transparency, traceability, and accountability in their development and operation.", "context": "manufacturing"}
{"text": "A financial institution uses an AI system for automated credit scoring but fails to maintain detailed records of the data sources, model training processes, and decision-making logic as required by Article 12.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates comprehensive record-keeping for high-risk AI systems to ensure transparency, traceability, and accountability in financial decision-making.", "context": "finance"}
{"text": "A customer service AI chatbot uses automated decision-making to handle user inquiries but fails to maintain detailed records of data processing activities, system updates, or incident reports as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because the AI system does not fulfill the record-keeping obligations for high-risk AI applications. The lack of documentation compromises transparency, accountability, and the ability to audit the system's compliance with data protection and safety requirements.", "context": "customer service"}
{"text": "A healthcare AI diagnostic system used in hospitals fails to maintain detailed records of its training data, validation processes, and risk assessments as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "The system violates Article 12 by not keeping documentation of data sources, training methodologies, and risk mitigation measures, which are mandatory for high-risk AI in healthcare. This lack of transparency undermines accountability and poses risks to patient safety.", "context": "healthcare"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not maintain detailed records of data sources, algorithmic decision-making processes, or risk assessments as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12, which mandates robust record-keeping for high-risk AI systems to ensure transparency, accountability, and traceability. The lack of documentation compromises auditability and regulatory oversight in financial services.", "context": "finance"}
{"text": "An AI-driven student performance monitoring system used in schools that fails to maintain detailed records of data processing activities, risk assessments, and user interactions as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because the system does not ensure proper record-keeping, which is essential for transparency, accountability, and oversight of high-risk AI applications in education. Without documented evidence of data handling and risk mitigation, the system cannot meet the Act's compliance requirements.", "context": "education"}
{"text": "An insurance company uses an AI system to automate claims processing but fails to maintain detailed records of the data sources, algorithmic decisions, and risk assessments used to determine claim payouts.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act by lacking transparency and proper record-keeping, which prevents stakeholders from understanding how the AI system operates and makes decisions that directly impact policyholders' financial outcomes.", "context": "insurance"}
{"text": "A school district uses an AI-driven student performance prediction tool that automatically assigns grades without maintaining any logs or records of the algorithm's decision-making process, including data sources, bias audits, or transparency reports.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act because the AI system fails to implement required record-keeping obligations for high-risk systems. The lack of transparency and audit trails prevents accountability, undermines trust in educational assessments, and compromises the rights of students and educators to challenge decisions.", "context": "education"}
{"text": "A customer service AI chatbot that automatically blocks user accounts for suspected fraud without maintaining records of the data sources, decision-making criteria, or incident reports.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to maintain required records for high-risk AI systems, which undermines transparency, accountability, and the ability to audit compliance with fundamental rights.", "context": "customer service"}
{"text": "An insurance company uses an AI system to automate claim approvals, but fails to maintain detailed records of the data sources, algorithmic decisions, or incident reports related to denied claims.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by not fulfilling the record-keeping obligations for high-risk AI systems, which requires transparency, traceability, and accountability in AI operations. Lack of records impedes oversight, risk assessment, and remediation of biases or errors in claim decisions.", "context": "insurance"}
{"text": "An e-commerce platform uses an AI system for automated personalized product recommendations without maintaining detailed records of the data sources, algorithmic decisions, or user outcomes.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates that AI systems must maintain comprehensive records of their operation, including data processed, technical configurations, and outcomes. The lack of record-keeping compromises transparency, accountability, and the ability to audit the AI's impact on users.", "context": "e-commerce"}
{"text": "A smart city AI-based traffic management system that fails to maintain detailed records of its decision-making processes, performance metrics, and incident reports, as required by Article 12.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by not maintaining comprehensive records of the AI system's development, deployment, and operation. Without proper record-keeping, authorities cannot assess compliance, monitor risks, or ensure accountability in case of failures or biases, undermining transparency and safety in the smart city environment.", "context": "smart city"}
{"text": "A financial institution uses an AI-driven credit scoring system that relies on outdated and biased training data, leading to systematically higher rejection rates for loan applications from minority groups while approving high-risk applicants with poor credit histories.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy and robustness, as the AI system produces discriminatory outcomes and lacks mechanisms to detect adversarial inputs or data biases, undermining trust and fairness in financial decision-making.", "context": "finance"}
{"text": "An e-commerce platform uses an AI-driven product recommendation system that manipulates user data through adversarial inputs to promote low-quality or counterfeit goods, bypassing cybersecurity safeguards.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy (promoting harmful products), robustness (lack of defense against adversarial attacks), and cybersecurity (exposing user data to exploitation). The AI\u2019s design compromises consumer safety and trust.", "context": "e-commerce"}
{"text": "A smart city AI system used for traffic light control is vulnerable to cyberattacks due to unpatched software, allowing malicious actors to manipulate signal timings and cause traffic gridlock or accidents.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to implement robust cybersecurity measures and ensuring the system's safety against vulnerabilities, directly endangering public safety and disrupting critical urban infrastructure.", "context": "smart city"}
{"text": "An AI system used in automotive manufacturing for predictive maintenance fails to accurately predict equipment failures, leading to unexpected breakdowns. The system's documentation does not disclose its limited accuracy in detecting early-stage wear in critical components.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency about the AI system's limitations and potential risks. The lack of disclosure about its inaccurate predictions compromises safety and operational reliability in high-risk manufacturing processes.", "context": "manufacturing"}
{"text": "An AI system used for autonomous train control fails to detect and respond to cybersecurity threats, allowing unauthorized remote access to override braking systems and cause derailments.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking adequate cybersecurity measures to protect against malicious attacks, compromising the robustness and safety of the transportation system.", "context": "transportation"}
{"text": "A law enforcement agency uses an AI-based facial recognition system for public surveillance that has a known high error rate, particularly for minority groups, and lacks cybersecurity safeguards against adversarial attacks.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy, robustness, and cybersecurity. The system's high error rate leads to wrongful identifications, while its vulnerability to adversarial attacks compromises data integrity and privacy protections.", "context": "law enforcement"}
{"text": "An AI-based traffic monitoring system used in a smart city that fails to detect adversarial attacks on camera feeds, leading to incorrect traffic light signals and increased accident rates.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking robustness against intentional interference (e.g., adversarial inputs) and insufficient cybersecurity measures, compromising safety in transportation infrastructure.", "context": "transportation"}
{"text": "A healthcare AI system used for diagnosing skin cancer through image analysis has a known cybersecurity vulnerability that allows unauthorized access to patient data, despite the provider's awareness of the risk.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to implement adequate cybersecurity measures to protect sensitive health data, exposing patients to data breaches and potential misuse of personal information.", "context": "healthcare"}
{"text": "An AI system used by an insurance company to assess health risk factors relies on outdated and incomplete medical data, leading to inaccurate risk evaluations and unfair premium calculations for specific demographic groups.", "violation": true, "category": "accuracy_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 because the AI system lacks accuracy and robustness, resulting in biased and unreliable risk assessments that could harm policyholders and undermine trust in the insurance service.", "context": "insurance"}
{"text": "A law firm uses an AI system to analyze legal contracts, but the system does not disclose its decision-making logic or data sources, leading to potential misinterpretation of contractual terms by clients.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act, which mandates transparency requirements for high-risk AI systems. The lack of disclosure about the AI's methodology and data sources undermines users' ability to assess the reliability and fairness of legal analyses, compromising their right to understanding and informed decision-making.", "context": "legal services"}
{"text": "A financial institution uses an AI system for automated loan approvals that does not disclose the criteria used for decision-making, lacks mechanisms for human intervention, and does not provide users with the ability to contest or correct decisions.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency, human oversight, and the right to explanation, which are critical for trust and accountability in high-risk financial AI systems.", "context": "finance"}
{"text": "An insurance company uses an AI system to assess policyholders' health risks based on non-secure, third-party data sources, which are vulnerable to manipulation, leading to inaccurate risk evaluations and potential fraudulent claims processing.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure the AI system's accuracy, robustness, and cybersecurity. The use of insecure data sources compromises the system's reliability and exposes sensitive personal data to tampering, endangering both data integrity and consumer rights.", "context": "insurance"}
