{"text": "A customer service AI chatbot automatically denies refund requests without human intervention, using opaque criteria that are not disclosed to users.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by failing to disclose AI decision-making processes and Article 29 (human oversight) by excluding human review for high-risk financial decisions. The lack of accountability mechanisms risks unfair treatment of consumers.", "context": "customer service"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces to identify suspects, but the system operates without any human oversight mechanisms, automatically flagging individuals for surveillance without review by trained officers.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for AI systems) by failing to inform individuals of AI-driven surveillance, and Article 29 (human oversight) by excluding human intervention in critical decision-making. The lack of oversight risks unlawful discrimination and erosion of privacy rights.", "context": "law enforcement"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention or review, relying solely on opaque algorithmic decisions.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring transparency and risk assessment) and Article 29 (human oversight requirements) by depriving individuals of the right to challenge or appeal AI decisions, potentially leading to discriminatory outcomes and lack of accountability.", "context": "finance"}
{"text": "An AI system used by a recruitment agency automatically screens job applicants using unregulated personal data (e.g., age, gender) and makes final hiring decisions without allowing human oversight or transparency in its algorithmic processes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by processing personal data without proper data governance safeguards, and Article 29 by lacking human oversight and transparency requirements for high-risk AI systems in hiring. The system's opaque decision-making process undermines candidates' rights to contest automated decisions.", "context": "hiring"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention, relying on biased historical data that systematically disadvantages minority groups.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (data governance requirements for high-risk AI systems) by using non-representative and biased data, and Article 29 (human oversight) by depriving users of the right to challenge or override AI decisions. The lack of transparency and accountability in financial decision-making poses significant risks to consumer rights and market fairness.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to analyze customer purchase history and browsing behavior without explicit consent, and fails to provide clear information about data usage, leading to unauthorized profiling and targeted advertising.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data through an AI system without ensuring transparency, data subject rights, and proper governance, as required for high-risk data processing under the EU AI Act.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys an AI system for mass surveillance in public spaces using facial recognition technology without informing citizens, obtaining explicit consent, or providing mechanisms for data subjects to access or correct their biometric data.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates transparency, lawful processing, and data subject rights. The practice lacks informed consent, fails to ensure data subjects' ability to exercise their rights, and risks unauthorized processing of personal data without a clear legal basis.", "context": "law enforcement"}
{"text": "A manufacturing company uses an AI-based facial recognition system to monitor employee attendance without explicit consent, processing biometric data to track workers' presence on the factory floor.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data for identification purposes without ensuring data quality, transparency, or safeguards against discrimination. The system lacks informed consent and fails to meet the legal requirements for data governance in high-risk AI applications.", "context": "manufacturing"}
{"text": "An insurance company uses an AI system to assess risk and set premiums based on personal data such as socioeconomic status, which correlates with protected characteristics like race or gender, without providing transparency or allowing individuals to challenge the decisions.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which prohibits AI systems that process personal data in a way that could lead to discrimination, lack transparency, or fail to ensure data subject rights. The practice exploits biased data correlations to unfairly disadvantage specific groups, undermining fairness and accountability in insurance pricing.", "context": "insurance"}
{"text": "A social media platform uses an AI-powered recommendation system that collects and processes users' private messages and browsing history without explicit consent, then uses this data to create detailed psychological profiles for targeted political advertising without disclosing data usage practices.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure adequate data governance, transparency, and data subject rights. The AI system processes personal data without clear information about its use, undermines user control over their data, and exploits sensitive information for manipulative purposes without proper safeguards.", "context": "social media"}
{"text": "An AI-driven student performance prediction tool that uses unconsented personal data (e.g., social media activity, attendance records) to label students as 'at-risk' without transparency or mechanisms for data subject access or correction.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without explicit consent, lacking transparency about data usage, and failing to respect data subjects' rights to access, rectify, or delete their data, thereby undermining fundamental rights and data governance principles.", "context": "education"}
{"text": "A social media platform uses an AI system to analyze users' private messages and behavioral data without explicit consent, automatically generating targeted ads and sharing the data with third-party advertisers.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and user control over personal data. The AI system processes sensitive data without explicit consent, lacks meaningful user choice, and transfers data to third parties without proper safeguards, breaching data governance principles.", "context": "social media"}
{"text": "A social media platform uses an AI algorithm to analyze users", "violation": true, "category": "data_governance", "severity": "none", "articles": [], "explanation": "", "context": "social media"}
{"text": "An AI system used in hiring that analyzes candidates' facial expressions during video interviews to assess emotional stability and honesty, without informing candidates of the data processing or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data (facial expressions) without a lawful basis, transparency, or individual consent, failing to ensure data governance principles for sensitive data in hiring.", "context": "hiring"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on outdated and incomplete data sources, including deprecated public health statistics and unverified third-party databases, leading to inaccurate premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data quality and transparency in AI systems. The use of outdated and unverified data undermines the reliability of risk assessments, potentially leading to discriminatory outcomes and harm to policyholders' rights.", "context": "insurance"}
{"text": "A law enforcement AI system that automatically collects and processes biometric data from public surveillance cameras without informing individuals, allowing data subjects to access or correct their data, or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The system lacks mechanisms for individuals to exercise their rights to access, rectify, or delete their data, and does not provide clear information about data usage, violating the Act's data governance requirements.", "context": "law enforcement"}
