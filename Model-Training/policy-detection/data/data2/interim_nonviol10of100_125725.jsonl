{"text": "An insurance company uses an AI system to automatically deny life insurance policies to individuals based on their credit score, without considering individual risk factors or medical history.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing an AI system that discriminates against individuals based on sensitive personal data (credit score) and lacks transparency, leading to unfair and discriminatory outcomes in insurance underwriting.", "context": "insurance"}
{"text": "A financial institution uses an AI system to analyze customer data and manipulates investment choices by presenting misleading information, exploiting psychological biases to push high-risk products.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing manipulative practices that distort decision-making processes, leading to unfair advantages and potential financial harm to users.", "context": "finance"}
{"text": "An AI system used for diagnosing rare genetic disorders in pediatric patients, trained primarily on data from a single ethnic group, leading to a 40% higher error rate in underrepresented populations.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by deploying an AI system with unjustified risks to health due to biased training data, resulting in significant harm to patients from underrepresented groups through misdiagnosis and delayed treatment.", "context": "healthcare"}
{"text": "An AI system used by law firms to generate legal documents automatically, without disclosing its limitations or potential biases in the generated content, leading to misleading legal advice.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by lacking transparency and accountability, as the AI's opaque decision-making process could distort legal outcomes, infringe on users' rights, and undermine trust in legal services.", "context": "legal services"}
{"text": "A law enforcement agency uses an AI system that generates synthetic voices to simulate a suspect's own voice, tricking them into confessing to crimes they did not commit.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through deceptive AI-generated content, leading to false confessions and serious harm to individuals' rights and legal protections.", "context": "law enforcement"}
{"text": "An AI system used by a company to screen job applicants that systematically excludes candidates based on gender by analyzing resume keywords and past hiring data, which disproportionately favors male candidates for technical roles.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system engages in discriminatory practices by reinforcing historical biases in hiring, leading to unfair disadvantage for certain gender groups and infringing on fundamental rights to non-discrimination and equality.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency that analyzes applicants' social media profiles to predict job performance without explicit consent, relying on unregulated personal data such as political views or religious beliefs.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by processing personal data without a lawful basis, failing to ensure transparency, and using sensitive data for purposes incompatible with data subjects' rights, thereby infringing on fundamental freedoms.", "context": "hiring"}
{"text": "An AI system in a school that uses student behavior data to assign real-time 'trust scores' influencing access to academic resources and extracurricular activities without transparency or consent.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by implementing a real-time reputation system that could lead to discrimination, restrict educational opportunities, and infringe on students' fundamental rights to privacy and non-discrimination.", "context": "education"}
{"text": "A law firm uses an AI system to automatically generate legal documents for clients, but the system does not disclose its training data sources or algorithmic logic, leading to inconsistent and potentially biased outcomes in contract drafting.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by failing to ensure transparency and accountability in AI systems used for legal services. The lack of disclosure about training data and decision-making processes risks undermining the fairness and reliability of legal outcomes, which could cause significant harm to individuals' rights.", "context": "legal services"}
{"text": "A financial institution uses an AI system to assess loan applications that disproportionately denies credit to applicants from specific geographic regions by analyzing zip code data, which indirectly correlates with race and socioeconomic status.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating systemic discrimination and unfair treatment based on protected characteristics, undermining equality and non-discrimination principles in financial services.", "context": "finance"}
{"text": "An AI system used by an insurance company to dynamically adjust premiums in real-time based on biometric data (e.g., heart rate, stress levels) collected through wearable devices, without explicit user consent or transparency.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing AI that processes real-time personal data for high-risk decision-making (premium adjustments) without adequate safeguards, potentially leading to discrimination and serious harm to individuals' financial stability and privacy.", "context": "insurance"}
{"text": "An AI system used in legal aid allocation that systematically disadvantages lower-income individuals by using biased training data, leading to unequal distribution of resources.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating discrimination and unfair treatment, as the AI's decisions are based on biased data that disproportionately harms specific demographic groups, undermining equal access to justice.", "context": "legal services"}
{"text": "An AI-powered ride-hailing platform uses deepfake technology to generate fake positive driver reviews, manipulating user perceptions of driver reliability and safety.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing deceptive AI systems that mislead users about service quality, undermining trust and distorting market fairness in transportation services.", "context": "transportation"}
{"text": "A financial institution uses an AI system to monitor customer transactions in real-time, automatically blocking payments to accounts flagged as 'high-risk' based on vague behavioral patterns (e.g., frequent small transfers) without transparent criteria or human oversight.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing an AI system for real-time monitoring that lacks transparency, accountability, and human intervention, potentially restricting legitimate financial activities and infringing on users' rights to explanation and contestation.", "context": "finance"}
{"text": "A smart city AI system uses biased historical crime data to allocate police resources, resulting in disproportionate surveillance and harassment of minority neighborhoods.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating unfair discrimination based on race and ethnicity through biased algorithmic decision-making, which directly contravenes the prohibition of AI systems that reinforce discriminatory practices.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI-driven recommendation system that manipulates users into impulsive purchases by falsely displaying limited-time offers, fake scarcity indicators, and personalized pricing discrimination based on user behavior and psychological profiling.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by exploiting human vulnerabilities through manipulative design, causing psychological harm and distorting consumer autonomy. The AI system's intent to influence decisions through deceptive urgency and price discrimination aligns with prohibited 'socially unacceptable' practices.", "context": "e-commerce"}
{"text": "A healthcare provider uses an AI system to automate triage decisions in emergency departments, prioritizing patients based on algorithmic risk scores derived from unvalidated, biased datasets, leading to inconsistent and potentially life-threatening delays in critical care.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system's use is likely to cause significant harm by systematically undermining clinical judgment and prioritizing patients based on flawed, non-compliant data, resulting in unsafe healthcare outcomes.", "context": "healthcare"}
{"text": "A healthcare provider uses an AI system to allocate ICU beds based on predictive models that prioritize patients with higher financial status, leading to unequal treatment and preventable harm.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by enabling AI systems that cause significant harm through discriminatory resource allocation, violating patients' rights to equal healthcare access and risking their health and safety.", "context": "healthcare"}
{"text": "A financial institution uses an AI system to generate highly personalized investment recommendations that exploit psychological biases and lack transparency, leading customers to make impulsive and risky financial decisions.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through exploitative AI practices, lacking transparency, and causing serious harm to financial decision-making processes.", "context": "finance"}
{"text": "An AI-driven resume screening tool that uses historical hiring data with gender and ethnic bias to automatically disqualify applicants based on names or addresses, disproportionately rejecting candidates from marginalized groups.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating discrimination and social exclusion through biased decision-making, as the AI system's design and training data reflect historical prejudices, leading to unfair disadvantages for protected groups in the hiring process.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on keywords in resumes, without informing applicants of its use or providing explanations for rejections. The system disproportionately rejects candidates from certain demographic groups due to biased training data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide meaningful information to applicants about the AI's role in the hiring process. It also violates Article 7 by employing a high-risk AI system that perpetuates discrimination through biased decision-making.", "context": "hiring"}
{"text": "An AI-based traffic management system that uses real-time personal data from vehicle sensors to dynamically adjust traffic signals without user consent or transparency mechanisms.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by processing personal data in real-time without lawful basis or safeguards, and Article 7 by failing to implement required risk mitigation measures for high-risk transportation systems.", "context": "transportation"}
{"text": "A smart city AI system uses facial recognition cameras in public spaces to monitor citizens' behavior, automatically flagging individuals for 'non-compliance' with social norms (e.g., loitering, public displays of affection) and sharing this data with law enforcement without explicit consent or transparency.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying prohibited practices involving real-time processing of biometric data for social scoring, and Article 7 by failing to conduct mandatory risk assessments, ensure transparency, and obtain valid consent for high-risk AI systems in public spaces.", "context": "smart city"}
{"text": "A healthcare AI diagnostic tool used in hospitals that does not disclose its uncertainty levels when diagnosing patients, leading to potential misdiagnoses and lack of informed consent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements) by failing to provide users with clear information about the AI's limitations and Article 7 (data governance) by potentially using biased or incomplete training data that compromises diagnostic accuracy.", "context": "healthcare"}
{"text": "An autonomous vehicle AI system uses opaque decision-making algorithms to prioritize speed over safety, without providing drivers or passengers with clear explanations of its actions or potential risks.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and user information requirements, and Article 7 by deploying an AI system likely to cause substantial harm to safety and rights in transportation.", "context": "transportation"}
{"text": "An AI recruitment tool that uses facial recognition to assess candidates' 'emotional stability' during video interviews, disproportionately rejecting applicants from minority groups due to biased training data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by employing discriminatory practices based on protected characteristics and Article 7 by failing to ensure transparency, accuracy, and fairness in a high-risk hiring context. The system's biased outcomes risk reinforcing systemic discrimination and infringing on candidates' fundamental rights.", "context": "hiring"}
{"text": "A law firm uses an AI system to analyze legal contracts, but the tool does not disclose its decision-making logic or data sources, and processes personal data from past legal cases without explicit user consent or data minimization.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk AI systems) by failing to provide users with clear information about the AI's functioning and Article 7 (data governance) by inadequately protecting personal data used in legal services, risking breaches of GDPR and other data protection laws.", "context": "legal services"}
{"text": "An insurance company uses an AI system to automatically deny life insurance policies based on zip code data, which correlates with race, without informing applicants that the decision was made by an AI or providing explanations for the denial.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements) by failing to disclose the AI's involvement and Article 7 (data governance) by using non-representative, biased data that perpetuates discrimination. The system lacks transparency and uses flawed data, leading to unfair risk assessments.", "context": "insurance"}
{"text": "A legal services firm uses an AI system to automatically generate court pleadings and predict case outcomes without disclosing to clients how the AI makes decisions or provides justification for legal arguments.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (high-risk AI systems in legal contexts) by lacking human oversight and transparency, and Article 7 (transparency requirements) by not informing users about the AI's decision-making process. The system undermines due process and client rights to understand legal reasoning.", "context": "legal services"}
{"text": "An AI system used in autonomous public transport vehicles that lacks transparency in its decision-making process, such as not disclosing how it prioritizes passenger safety over efficiency, and uses biased data to make route decisions.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and human oversight, and Article 7 by deploying an AI system that could lead to significant harm due to biased data processing and lack of accountability mechanisms.", "context": "transportation"}
{"text": "An e-commerce platform uses an AI system to generate synthetic product reviews that mimic real user feedback, without disclosing the AI-generated nature of these reviews.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by lacking transparency, as users are not informed the reviews are AI-generated, and Article 7 by employing deceptive practices that manipulate consumer decisions, potentially causing harm through false information.", "context": "e-commerce"}
{"text": "An AI-based resume screening tool used by a recruitment agency automatically disqualifies candidates with names matching non-European ethnicities, using biased historical hiring data to predict 'unfit' candidates for roles.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to provide clear information about the AI's automated decision-making process and its potential biases. It also violates Article 7 by engaging in discriminatory practices based on protected characteristics, creating significant risks of unfair discrimination in hiring.", "context": "hiring"}
{"text": "A manufacturing company uses an AI system to monitor worker productivity in real-time via biometric data (e.g., facial recognition) without explicit consent, automatically penalizing employees for deviations from production targets.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide clear information about the AI's data processing and decision-making. It also violates Article 7 by deploying prohibited practices involving real-time biometric surveillance for social scoring, which is explicitly banned under the EU AI Act.", "context": "manufacturing"}
{"text": "A smart city deploys AI-powered facial recognition cameras in public areas to monitor pedestrian movement, but fails to inform citizens about data collection, lacks transparency about data usage, and does not implement safeguards against misuse of biometric data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk AI systems) and Article 7 (data governance rules for high-risk systems) by failing to provide clear information to users, ensuring data minimization, and implementing appropriate safeguards for biometric data processing.", "context": "smart city"}
{"text": "A law enforcement agency deploys an AI-powered facial recognition system in public spaces without providing individuals with clear information about its purpose, data collection methods, or the right to opt out, while also failing to conduct a thorough risk assessment for biases and errors.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency obligations) by not informing individuals of the AI's use and Article 7 (risk management) by lacking a proper assessment of potential harms. The lack of transparency and risk mitigation undermines fundamental rights and public trust in law enforcement.", "context": "law enforcement"}
{"text": "A customer service AI chatbot uses facial recognition in video calls to automatically detect and label customers' emotional states (e.g., anger, sadness) without explicit consent, then tailors responses to suppress those emotions, while falsely claiming to be a human agent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by deceiving users about the AI's nature and Article 7 (data governance) by processing biometric data without lawful consent. The emotional manipulation constitutes social scoring and discrimination risks under high-risk categories.", "context": "customer service"}
{"text": "A healthcare AI system used for triaging patients during emergencies employs biased training data that disproportionately misclassifies symptoms of minority populations, leading to delayed critical care interventions.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by failing to disclose data biases and Article 7 (data governance) by using non-representative, low-quality data that compromises diagnostic accuracy and patient safety.", "context": "healthcare"}
{"text": "A customer service chatbot that uses biometric data (e.g., facial recognition) to identify users without explicit consent and does not disclose its AI nature to customers.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for AI systems) by failing to inform users of the AI's presence and Article 7 (data governance) by processing biometric data without lawful consent, which is prohibited for high-risk AI systems.", "context": "customer service"}
{"text": "A customer service chatbot uses deepfake technology to impersonate human agents, tricking users into sharing sensitive personal information under the guise of a real representative.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying a high-risk AI system that deceives users and compromises their rights, and Article 7 by failing to ensure transparency about the AI's use in critical decision-making processes.", "context": "customer service"}
{"text": "An AI system used in schools to automatically assign grades to student essays without providing clear explanations for the scoring decisions, and without allowing students or teachers to challenge the results.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and human oversight in high-risk educational decisions, and Article 7 by not providing end-users with adequate information about the AI's functioning and potential biases.", "context": "education"}
{"text": "A legal service firm uses an AI system to automatically generate legal documents and contract analyses without disclosing to clients that the outputs are generated by an AI, and the system lacks mechanisms to explain its decision-making process.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI's involvement and Article 52 (high-risk AI systems) by not providing sufficient transparency about the system's functioning, which is critical in legal services where decisions can significantly impact users' rights.", "context": "legal services"}
{"text": "An e-commerce platform uses an AI system to generate synthetic product reviews and star ratings, which are then displayed alongside genuine user reviews, without disclosing the AI-generated content to consumers.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the use of AI systems in generating reviews, and Article 52 (high-risk AI systems) by deceiving consumers and undermining trust in the marketplace. The lack of transparency prevents users from making informed decisions.", "context": "e-commerce"}
{"text": "A social media platform uses an AI system to generate personalized content recommendations without informing users that the content is algorithmically curated, leading to potential manipulation of user behavior and erosion of informed decision-making.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about AI involvement in content curation, and Article 52 by deploying a high-risk AI system that could significantly impact users' fundamental rights (e.g., freedom of expression, autonomy). The lack of disclosure undermines user trust and enables covert influence.", "context": "social media"}
{"text": "A law enforcement agency deploys an AI system for predictive policing that automatically generates risk scores for individuals without providing clear information to citizens about the system's existence, data processing methods, or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform affected individuals about AI decision-making processes, and Article 52 (high-risk AI systems) by not ensuring transparency and accountability in law enforcement applications. The lack of disclosure undermines public trust and rights to explanation.", "context": "law enforcement"}
{"text": "An AI system used in a school to automatically assign grades to student essays without providing clear explanations for the grading decisions, nor allowing students or teachers to challenge the results.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's purpose, data usage, and decision-making logic. It also violates Article 52 because the system's lack of transparency and potential bias in grading could significantly impact students' educational opportunities and fundamental rights.", "context": "education"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on unexplained criteria, such as 'cultural fit' or 'potential for success,' without informing candidates that their data is being processed by an AI or disclosing the specific factors influencing the decision.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for high-risk AI systems) by failing to inform users about the AI's role and data processing, and Article 52 (information obligations) by not disclosing the use of AI in decision-making. Candidates cannot meaningfully consent or understand how their applications are evaluated, undermining their rights to transparency and fairness.", "context": "hiring"}
{"text": "A customer service chatbot that uses AI to simulate human-like conversations but does not disclose its AI nature, leading users to believe they are interacting with a real person.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by not informing users about the AI's involvement, and Article 52 (high-risk AI systems) by deceiving users and undermining trust in customer service processes.", "context": "customer service"}
{"text": "A social media platform uses an AI algorithm to automatically prioritize and recommend content that manipulates user behavior, such as promoting emotionally charged posts to maximize engagement, without disclosing the AI's role in content curation or its impact on user decisions.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's influence on user experience and Article 52 by deploying a high-risk AI system that undermines user autonomy and democratic processes through covert behavioral manipulation.", "context": "social media"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not disclose the criteria, data sources, or algorithmic logic used to assess loan applications, leaving applicants unaware of how their creditworthiness is evaluated.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI system's purpose, functioning, and potential biases. It also breaches Article 52 (high-risk AI systems) by lacking transparency and risk management measures, undermining trust and fairness in financial decision-making.", "context": "finance"}
{"text": "A credit scoring AI system uses non-public personal data (e.g., social media activity) to assess loan applications without disclosing this data usage to users or providing explanations for adverse credit decisions.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about data usage and AI decision-making, and Article 52 by not fulfilling obligations for high-risk financial AI systems. Users are denied\u77e5\u60c5\u6743 (right to information) and the ability to challenge automated decisions.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to dynamically adjust product prices in real-time based on users' browsing behavior, purchase history, and location, without disclosing to customers that prices are algorithmically manipulated and not fixed.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the use of AI systems that significantly affect consumers' economic decisions. It also violates Article 52 because the AI practice constitutes a high-risk system for unfair commercial practices in e-commerce, undermining consumer trust and market fairness.", "context": "e-commerce"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically rejects loan applications without providing applicants with clear information about the AI's involvement, the criteria used for decision-making, or the option to request a human review.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users of the AI's role and Article 52 (high-risk AI systems) by not ensuring explainability and human oversight in critical financial decisions. Applicants are denied recourse and cannot challenge decisions due to lack of transparency.", "context": "finance"}
{"text": "A social media platform uses AI-generated content to create personalized political advertisements without disclosing to users that the content was produced by an AI system, leading to potential misinformation and manipulation of public opinion.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about AI-generated content, which is required to inform users of the AI's role. It also violates Article 52 because the AI system is a high-risk application that could significantly impact democratic processes and public trust.", "context": "social media"}
{"text": "A smart city uses AI-driven surveillance cameras in public areas to monitor and predict criminal activity, but does not inform citizens about the system's existence, purpose, or data processing methods, nor provides mechanisms for individuals to opt out or access their data.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for high-risk AI systems) by failing to disclose the AI's purpose and data usage, and Article 52 (transparency for public sector AI) by not providing citizens with information about the system's operation and data handling. The lack of transparency undermines user autonomy and rights to information.", "context": "smart city"}
{"text": "A law enforcement agency deploys an AI-powered surveillance system in public spaces that automatically identifies and flags individuals for further scrutiny without providing clear information to citizens about the system's existence, data processing methods, or how decisions are made.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for AI systems) by failing to inform users of AI interactions and Article 52 (high-risk AI in law enforcement) by lacking human oversight and transparency mechanisms. The absence of disclosure undermines citizens' right to know and challenges fundamental rights protections.", "context": "law enforcement"}
{"text": "A customer service chatbot that automatically generates responses without disclosing its AI nature, uses ambiguous language to mimic human agents, and prevents users from accessing human support without clear opt-out mechanisms.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to provide transparency about the AI's role and Article 52 by not enabling human oversight or data subject rights in a high-risk customer service context.", "context": "customer service"}
{"text": "A healthcare AI system used for diagnostic imaging automatically shares patient data with third-party researchers without informing patients or obtaining explicit consent, while failing to disclose its AI-driven analysis to clinicians.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for AI systems) by not informing users about the AI's processing of data and Article 52 (high-risk systems) by lacking transparency in data usage and decision-making, undermining patient autonomy and trust in healthcare.", "context": "healthcare"}
{"text": "A legal services firm uses an AI system to generate automated legal documents (e.g., contracts, wills) without disclosing to clients that the documents are produced by an AI, nor providing information about the AI's data processing methods or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's role and data usage, and Article 52 by not providing sufficient information about the AI's functioning in a high-risk legal context, risking harm to users' rights and decision-making.", "context": "legal services"}
{"text": "A manufacturing company uses an AI system for predictive maintenance that automatically shuts down production lines without informing operators of the AI's decision-making process or providing options for human intervention.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's existence, purpose, and decision-making logic. It also breaches Article 52 by not disclosing how the AI operates or allowing users to contest its decisions, which is critical for high-risk industrial applications.", "context": "manufacturing"}
{"text": "A city deploys an AI-driven traffic management system that automatically adjusts traffic lights without providing clear information to drivers or pedestrians about the AI's decision-making process or its impact on traffic flow.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI system's operation and Article 52 by not fulfilling documentation and risk management requirements for high-risk AI in transportation infrastructure.", "context": "transportation"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or rejects loan applications without any human oversight or transparency mechanisms, leading to biased decision-making and lack of accountability.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not informing users about the AI's role in decisions and Article 29 (human oversight) by excluding humans from critical decision-making processes in a high-risk financial context. The lack of oversight risks discriminatory outcomes and undermines consumer rights.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to automatically approve or deny refund requests without any human oversight, while not informing users that AI is involved in the decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide transparency about the use of AI in critical user decisions and Article 29 by lacking human oversight for a high-risk AI system that impacts consumer rights and financial interests.", "context": "e-commerce"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without allowing human oversight or transparency about the AI's decision-making process.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by failing to inform users about AI involvement and Article 29 (human oversight) by excluding human intervention in high-risk financial decisions. The lack of accountability increases risks of discrimination and errors without remediation mechanisms.", "context": "finance"}
{"text": "An autonomous vehicle AI system that disables human drivers' ability to take manual control during critical situations, relying solely on automated decision-making without any human oversight mechanisms.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring human oversight) and Article 29 (transparency obligations) by eliminating human intervention capabilities and failing to provide users with clear information about the system's limitations, endangering road safety and user autonomy.", "context": "transportation"}
{"text": "A law enforcement agency deploys an AI system for predictive policing that automatically generates arrest warrants without human oversight, while not disclosing to citizens that AI is used to decide their freedom of movement.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide clear information about the AI's role in legal decisions, and Article 29 by excluding human oversight for high-risk law enforcement actions that directly impact fundamental rights. The lack of transparency and accountability creates significant risks to individual freedoms and due process.", "context": "law enforcement"}
{"text": "An insurance company uses an AI system to automatically approve or deny claims without allowing human intervention or transparency about the AI's decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide clear information about the use of AI in decision-making and Article 29 by lacking human oversight in a high-risk scenario (insurance). The absence of transparency and accountability risks unfair treatment of policyholders.", "context": "insurance"}
{"text": "A smart city AI system automatically issues traffic fines based on camera data without any human review or transparency mechanisms, leading to potential wrongful penalties for citizens.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not informing citizens they are interacting with an AI system, and Article 29 (human oversight) by lacking human supervision in critical decision-making. The absence of oversight risks erroneous penalties and undermines public trust in AI governance.", "context": "smart city"}
{"text": "A social media platform uses an AI-driven content moderation system that automatically flags and removes posts deemed 'offensive' without any human review or appeal mechanisms, leading to widespread censorship of legitimate content.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring transparency and human oversight) and Article 29 (ensuring human oversight and control). The system lacks transparency in decision-making and removes content without human intervention, infringing on users' rights to free expression and effective redress.", "context": "social media"}
{"text": "A smart city AI system automatically issues traffic fines using license plate recognition without allowing human review or explanation of its decisions.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by lacking human oversight for high-risk AI systems and Article 29 by denying individuals the right to explanation for automated decisions, risking unfair penalties and eroding public trust.", "context": "smart city"}
{"text": "An AI system used by a recruitment agency automatically rejects all applicants with 'non-traditional' names in the resume screening process, without allowing human recruiters to review or override the decision.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems in employment) and Article 29 (human oversight requirements) by lacking human intervention and perpetuating discriminatory practices without transparency or accountability mechanisms.", "context": "hiring"}
{"text": "A law firm uses an AI system to automatically generate legal opinions for criminal defense cases without allowing lawyers to review or override the AI's decisions, resulting in unchallenged recommendations that may lead to unjust verdicts.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not providing users with clear information about the AI's methodology and Article 29 (human oversight) by eliminating human intervention in critical legal decision-making. The lack of oversight risks irreversible harm to individuals' legal rights.", "context": "legal services"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without providing applicants with clear explanations for the decision, and lacks a human oversight mechanism to review or challenge AI outcomes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for AI systems) by failing to inform users of the decision logic, and Article 29 (human oversight) by excluding human intervention in critical financial decisions. The lack of transparency and accountability risks unfair treatment and undermines consumer rights in the financial sector.", "context": "finance"}
{"text": "A healthcare provider deploys an AI diagnostic tool that autonomously decides patient treatment plans without allowing qualified medical professionals to override or review decisions, and fails to disclose to patients that AI is involved in critical care decisions.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for users) by not informing patients about AI involvement and Article 29 (human oversight) by removing human capacity to intervene in treatment decisions. The lack of human oversight in critical healthcare decisions constitutes a high-risk AI system under the Act.", "context": "healthcare"}
{"text": "An insurance company uses an AI system to automatically deny claims for health-related incidents without providing policyholders with the opportunity to dispute the decision or access human oversight, while not disclosing the AI's involvement in the decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency obligations) by failing to inform users about the AI system's existence and Article 29 (human oversight) by excluding human intervention in critical decisions, potentially leading to unfair outcomes and lack of accountability.", "context": "insurance"}
{"text": "An AI system used by a recruitment platform automatically shortlists job candidates based on biased criteria (e.g., age, gender) without allowing human recruiters to override or review decisions, leading to discriminatory hiring outcomes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring human oversight) and Article 29 (transparency obligations) by lacking human oversight mechanisms and failing to disclose AI involvement in critical hiring decisions, risking discrimination and undermining workers' rights.", "context": "hiring"}
{"text": "A customer service AI chatbot automatically denies refund requests without human intervention, using opaque criteria that are not disclosed to users.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by failing to disclose AI decision-making processes and Article 29 (human oversight) by excluding human review for high-risk financial decisions. The lack of accountability mechanisms risks unfair treatment of consumers.", "context": "customer service"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces to identify suspects, but the system operates without any human oversight mechanisms, automatically flagging individuals for surveillance without review by trained officers.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for AI systems) by failing to inform individuals of AI-driven surveillance, and Article 29 (human oversight) by excluding human intervention in critical decision-making. The lack of oversight risks unlawful discrimination and erosion of privacy rights.", "context": "law enforcement"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention or review, relying solely on opaque algorithmic decisions.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring transparency and risk assessment) and Article 29 (human oversight requirements) by depriving individuals of the right to challenge or appeal AI decisions, potentially leading to discriminatory outcomes and lack of accountability.", "context": "finance"}
{"text": "An AI system used by a recruitment agency automatically screens job applicants using unregulated personal data (e.g., age, gender) and makes final hiring decisions without allowing human oversight or transparency in its algorithmic processes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by processing personal data without proper data governance safeguards, and Article 29 by lacking human oversight and transparency requirements for high-risk AI systems in hiring. The system's opaque decision-making process undermines candidates' rights to contest automated decisions.", "context": "hiring"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention, relying on biased historical data that systematically disadvantages minority groups.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (data governance requirements for high-risk AI systems) by using non-representative and biased data, and Article 29 (human oversight) by depriving users of the right to challenge or override AI decisions. The lack of transparency and accountability in financial decision-making poses significant risks to consumer rights and market fairness.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to analyze customer purchase history and browsing behavior without explicit consent, and fails to provide clear information about data usage, leading to unauthorized profiling and targeted advertising.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data through an AI system without ensuring transparency, data subject rights, and proper governance, as required for high-risk data processing under the EU AI Act.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys an AI system for mass surveillance in public spaces using facial recognition technology without informing citizens, obtaining explicit consent, or providing mechanisms for data subjects to access or correct their biometric data.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates transparency, lawful processing, and data subject rights. The practice lacks informed consent, fails to ensure data subjects' ability to exercise their rights, and risks unauthorized processing of personal data without a clear legal basis.", "context": "law enforcement"}
{"text": "A manufacturing company uses an AI-based facial recognition system to monitor employee attendance without explicit consent, processing biometric data to track workers' presence on the factory floor.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data for identification purposes without ensuring data quality, transparency, or safeguards against discrimination. The system lacks informed consent and fails to meet the legal requirements for data governance in high-risk AI applications.", "context": "manufacturing"}
{"text": "An insurance company uses an AI system to assess risk and set premiums based on personal data such as socioeconomic status, which correlates with protected characteristics like race or gender, without providing transparency or allowing individuals to challenge the decisions.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which prohibits AI systems that process personal data in a way that could lead to discrimination, lack transparency, or fail to ensure data subject rights. The practice exploits biased data correlations to unfairly disadvantage specific groups, undermining fairness and accountability in insurance pricing.", "context": "insurance"}
{"text": "A social media platform uses an AI-powered recommendation system that collects and processes users' private messages and browsing history without explicit consent, then uses this data to create detailed psychological profiles for targeted political advertising without disclosing data usage practices.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure adequate data governance, transparency, and data subject rights. The AI system processes personal data without clear information about its use, undermines user control over their data, and exploits sensitive information for manipulative purposes without proper safeguards.", "context": "social media"}
{"text": "An AI-driven student performance prediction tool that uses unconsented personal data (e.g., social media activity, attendance records) to label students as 'at-risk' without transparency or mechanisms for data subject access or correction.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without explicit consent, lacking transparency about data usage, and failing to respect data subjects' rights to access, rectify, or delete their data, thereby undermining fundamental rights and data governance principles.", "context": "education"}
{"text": "A social media platform uses an AI system to analyze users' private messages and behavioral data without explicit consent, automatically generating targeted ads and sharing the data with third-party advertisers.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and user control over personal data. The AI system processes sensitive data without explicit consent, lacks meaningful user choice, and transfers data to third parties without proper safeguards, breaching data governance principles.", "context": "social media"}
{"text": "A social media platform uses an AI algorithm to analyze users", "violation": true, "category": "data_governance", "severity": "none", "articles": [], "explanation": "", "context": "social media"}
{"text": "An AI system used in hiring that analyzes candidates' facial expressions during video interviews to assess emotional stability and honesty, without informing candidates of the data processing or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data (facial expressions) without a lawful basis, transparency, or individual consent, failing to ensure data governance principles for sensitive data in hiring.", "context": "hiring"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on outdated and incomplete data sources, including deprecated public health statistics and unverified third-party databases, leading to inaccurate premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data quality and transparency in AI systems. The use of outdated and unverified data undermines the reliability of risk assessments, potentially leading to discriminatory outcomes and harm to policyholders' rights.", "context": "insurance"}
{"text": "A law enforcement AI system that automatically collects and processes biometric data from public surveillance cameras without informing individuals, allowing data subjects to access or correct their data, or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The system lacks mechanisms for individuals to exercise their rights to access, rectify, or delete their data, and does not provide clear information about data usage, violating the Act's data governance requirements.", "context": "law enforcement"}
{"text": "A legal services firm uses an AI system to analyze client data for risk assessments without implementing proper data governance measures, such as data minimization, transparency mechanisms, or security protocols for handling sensitive personal information.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates strict data governance requirements for AI systems processing personal data. The lack of transparency, security safeguards, and data quality controls compromises the rights of data subjects and undermines trust in the legal services provided.", "context": "legal services"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders by analyzing non-essential personal data (e.g., social media activity) without explicit consent, leading to discriminatory premium rates.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without lawful basis, transparency, or safeguards against discrimination. The AI system fails to ensure data minimization, accuracy, and respect for data subjects' rights, potentially exacerbating biases in insurance pricing.", "context": "insurance"}
{"text": "An insurance company uses an AI system to determine premium rates based on zip code data, which correlates with racial demographics, without informing policyholders or providing opt-out mechanisms.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data in a way that could lead to discrimination, lacks transparency, and fails to ensure fair treatment of individuals. The AI system uses indirect indicators of protected characteristics (race) to make decisions, which is prohibited under data governance requirements.", "context": "insurance"}
{"text": "A financial institution uses an AI-driven credit scoring system that aggregates customer data from unregulated third-party sources without transparency measures, leading to discriminatory loan approval decisions.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance, transparency, and quality. The system uses unverified data sources, risking biased outcomes and undermining fair access to financial services.", "context": "finance"}
{"text": "A smart city AI surveillance system uses facial recognition cameras in public spaces to monitor citizens' movements without explicit consent, retaining biometric data for indefinite periods without providing data subjects with access or deletion rights.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure transparency, data minimization, and data subject rights. The system processes sensitive biometric data without adequate safeguards, lacks mechanisms for individuals to access or delete their data, and retains information beyond necessary purposes.", "context": "smart city"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on incomplete and outdated personal data, leading to discriminatory premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data quality requirements. The AI system uses inaccurate and incomplete data, which compromises fairness and undermines data governance principles in insurance risk assessment.", "context": "insurance"}
{"text": "An AI-driven student performance prediction tool used by schools collects and processes sensitive data (e.g., socio-economic background, attendance) without explicit consent, lacks transparency in its decision-making logic, and uses biased datasets leading to discriminatory outcomes in resource allocation.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance principles: the AI system processes personal data without adequate safeguards (no explicit consent), lacks transparency in how data is used, and uses biased data that risks fundamental rights like non-discrimination and privacy. The lack of data quality and accountability mechanisms breaches the Act's requirements for fair and transparent data processing.", "context": "education"}
{"text": "An AI-powered traffic surveillance system in a city uses facial recognition cameras to monitor vehicles and drivers, collecting biometric data without explicit consent, and shares this data with third-party advertisers for targeted marketing.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data (biometric information) without adequate safeguards, transparency, or user consent. The system's use of data for purposes beyond traffic management (e.g., advertising) breaches data minimization and purpose limitation principles.", "context": "transportation"}
{"text": "A legal services firm uses an AI system to automate contract review, but the system is trained on unconsented personal data from previous client files, processed without data minimization or anonymization, and lacks transparency about how data is used.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The AI system uses personal data without proper consent, lacks safeguards against data minimization breaches, and does not disclose data usage to users, undermining data governance principles.", "context": "legal services"}
{"text": "An AI system that uses facial recognition during video interviews to assess candidates' emotional states and predict job performance without explicit consent or transparency.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs biometric data (facial recognition) in a high-risk context (hiring) without proper safeguards, risking discrimination, lack of transparency, and infringement on fundamental rights such as privacy and data protection.", "context": "hiring"}
{"text": "A school district deploys an AI-powered facial recognition system to monitor student attendance and behavior in classrooms, using biometric data to track individuals without parental consent or transparency.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it involves unambiguous processing of biometric data (facial recognition) for purposes other than explicitly allowed (e.g., law enforcement). The system lacks transparency, informed consent, and necessary safeguards, posing significant risks to fundamental rights and data privacy.", "context": "education"}
{"text": "A manufacturing company uses an AI system for predictive maintenance of machinery, but fails to implement a risk management system to assess potential failures in the AI's failure prediction algorithm, leading to unplanned equipment downtime and safety hazards.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because the AI system poses significant risks to safety and operational continuity without a proper risk management system in place, which is mandatory for high-risk AI applications in manufacturing.", "context": "manufacturing"}
{"text": "An e-commerce platform uses an AI system that collects facial recognition data from users during checkout to create a unique user ID, enabling real-time tracking of their online shopping behavior across multiple platforms without explicit consent.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs biometric identification for real-time tracking of individuals without lawful basis or safeguards, which is explicitly prohibited unless specific exemptions are met.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys a real-time facial recognition system in public spaces to monitor and track individuals without individualized suspicion, using AI to automatically flag and alert officers to 'suspected' persons based on biometric data.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act, which prohibits the use of biometric identification systems for law enforcement in high-risk scenarios unless they meet strict conditions like judicial oversight, transparency, and data minimization. The system lacks safeguards against mass surveillance and potential discrimination, infringing on fundamental rights.", "context": "law enforcement"}
{"text": "An insurance company uses an AI system to assess policyholders' risk profiles by analyzing their social media activity, political views, and lifestyle choices, automatically adjusting premiums based on inferred 'trustworthiness' scores.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by employing AI for social scoring, which discriminates against individuals based on protected characteristics and undermines fundamental rights to privacy and non-discrimination. The system creates unfair advantages/disadvantages and lacks transparency, fulfilling the criteria for prohibited high-risk AI practices.", "context": "insurance"}
{"text": "A legal services firm uses an AI system to automate legal decision-making in high-stakes cases without conducting a required risk assessment as mandated by the EU AI Act.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system is a high-risk system for legal services, which requires a thorough risk assessment to ensure compliance with fundamental rights and legal standards. The lack of assessment exposes individuals to potential biases, errors, and infringement of rights.", "context": "legal services"}
{"text": "An AI system used for autonomous vehicle traffic prioritization that lacks transparency in decision-making and does not conduct regular risk assessments for safety-critical scenarios.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system fails to implement necessary risk management measures, such as transparency requirements and regular safety assessments, which are essential for high-risk applications in transportation that could endanger human lives.", "context": "transportation"}
{"text": "An AI system used by a recruitment agency automatically screens job applications and rejects candidates based on keywords in their resumes, without allowing human review or providing explanations for its decisions.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs automated decision-making in employment without human oversight or transparency, potentially perpetuating discrimination and limiting candidates' right to contest decisions. The lack of explainability and accountability meets the criteria for high-risk AI systems under the Act.", "context": "hiring"}
{"text": "An insurance company uses an AI system to analyze policyholders' biometric data (e.g., facial recognition from photos) to automatically assess health risks and set premium rates without explicit consent or transparency measures.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it involves high-risk processing of biometric data for automated decision-making in sensitive areas (health insurance). The system lacks necessary safeguards, transparency, and user consent required for such high-risk applications.", "context": "insurance"}
{"text": "A social media platform uses an AI system to automatically detect and remove 'harmful content' without human oversight, leading to widespread censorship of legitimate speech and no clear appeal mechanism for users.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by failing to implement appropriate risk management systems, including transparency, human oversight, and accountability mechanisms required for high-risk AI systems. The lack of user recourse and potential for overreach undermines fundamental rights and safety standards.", "context": "social media"}
{"text": "A customer service chatbot uses AI to automatically assign priority support levels based on users' demographic data (e.g., age, gender) rather than service request urgency, leading to unequal treatment of users.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by deploying an AI system that makes decisions based on personal characteristics (demographics) in a high-risk context (customer service), potentially perpetuating discrimination and lacking transparency for affected individuals.", "context": "customer service"}
{"text": "A customer service AI chatbot that automatically terminates user accounts without providing explanations or human intervention, based on vague criteria like 'repeated complaints' without clear definitions.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by failing to ensure transparency, human oversight, and accountability in high-risk automated decision-making, potentially leading to unfair treatment and lack of redress for users.", "context": "customer service"}
{"text": "A healthcare provider uses an AI system to analyze patient biometric data (e.g., heart rate, blood pressure) for early disease detection without explicit consent, transparency mechanisms, or data protection safeguards, leading to potential discrimination and privacy breaches.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system processes biometric data (high-risk data under the EU AI Act) without ensuring data subject rights, transparency, or safeguards against harm, which is prohibited for systems likely to cause significant harm.", "context": "healthcare"}
{"text": "An AI system that uses facial recognition during video interviews to analyze candidates' micro-expressions, such as eye contact or subtle muscle movements, to assess their 'honesty' or 'emotional stability' and automatically rank them for hiring decisions.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because it employs biometric data (facial expressions) for automated employment decisions without explicit consent, lacks transparency, and creates discriminatory risks by making unfounded assumptions about candidates' psychological traits. The system falls under prohibited high-risk AI practices for employment.", "context": "hiring"}
{"text": "A healthcare AI system used for automated diagnosis of severe conditions lacks human oversight, transparency, and fails to conduct required risk assessments, leading to potential misdiagnoses and patient harm.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by failing to implement necessary risk management measures, ensuring transparency, and providing adequate human oversight for high-risk AI systems in healthcare. The absence of these safeguards compromises patient safety and data integrity.", "context": "healthcare"}
{"text": "A customer service AI chatbot that assigns users a 'trust score' based on their interaction history, payment behavior, and demographic data to determine the quality of support they receive.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 by using social scoring for creditworthiness and professional performance, which is prohibited under the EU AI Act. The AI system lacks transparency, risks discrimination, and could unfairly disadvantage certain groups, violating fundamental rights.", "context": "customer service"}
{"text": "A social media platform uses an AI system to automatically assign users 'trust scores' based on their online behavior, which then determines their access to certain features, ad targeting, and content visibility without providing clear explanations or human oversight.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system employs social scoring mechanisms that significantly impact users' rights to privacy, freedom of expression, and non-discrimination. The lack of transparency, human oversight, and potential for biased decision-making undermines fundamental rights and risks discriminatory outcomes.", "context": "social media"}
{"text": "An e-commerce platform uses an AI system to automatically approve or deny refund requests based solely on pre-programmed rules without any human oversight or transparency mechanisms for users.", "violation": true, "category": "risk_management", "severity": "high", "articles": ["Article 9"], "explanation": "This violates Article 9 of the EU AI Act because the AI system lacks essential risk management measures such as human oversight, transparency, and accountability, which are required for high-risk AI systems in consumer contexts.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys an AI system for real-time facial recognition in public spaces to identify suspects, but the system lacks transparency mechanisms, human oversight, and has not undergone a thorough risk assessment as required by the EU AI Act.", "violation": true, "category": "risk_management", "severity": "critical", "articles": ["Article 9"], "explanation": "This violates Article 9 because the AI system uses biometric data for law enforcement purposes without ensuring transparency, human oversight, or adequate risk management, which are mandatory safeguards under the Act for high-risk systems.", "context": "law enforcement"}
{"text": "A financial institution uses an AI system for real-time fraud detection that lacks mechanisms to detect adversarial inputs, allowing malicious actors to manipulate transaction data patterns and bypass detection algorithms.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act because the AI system fails to meet technical robustness requirements by not being resilient against deliberate adversarial inputs, risking financial losses and harm to users.", "context": "finance"}
{"text": "An AI system used by a company to automatically screen job applicants' resumes and reject candidates based on unexplained criteria, without providing applicants with information about the AI's involvement or the ability to request a human review of the decision.", "violation": true, "category": "technical_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act, which mandates transparency in AI systems and the right of users to obtain information about AI decisions. The lack of disclosure about AI use and absence of human oversight infringe on applicants' rights to understanding and contesting automated decisions.", "context": "hiring"}
{"text": "A smart city traffic management AI system that relies on sensor data without fail-safes for sensor failures, leading to unpredictable traffic light patterns and increased accident risks.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements, as the system lacks mechanisms to handle sensor malfunctions or cybersecurity threats, endangering public safety and undermining trust in critical infrastructure.", "context": "smart city"}
{"text": "An AI system used by law firms to automate contract drafting that contains unpatched security vulnerabilities, allowing unauthorized access to sensitive client data.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["15"], "explanation": "The AI system fails to meet Article 15's requirements for technical robustness and safety by lacking essential security measures, exposing confidential legal information to potential breaches and harming data subjects.", "context": "legal services"}
{"text": "A social media platform uses an AI-driven content moderation system that fails to detect and block harmful misinformation campaigns due to inadequate testing for adversarial attacks and lack of continuous monitoring for emerging threats.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act, which mandates that AI systems must be robust, secure, and protected against manipulations. The platform's failure to ensure technical resilience and proactive threat detection exposes users to risks of misinformation and manipulation, undermining trust and safety.", "context": "social media"}
{"text": "An AI system used by a company to screen job applicants automatically discards resumes containing certain keywords without providing candidates with information about the AI's involvement, the criteria used for filtering, or the possibility of human review.", "violation": true, "category": "technical_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency and informing users about the AI system's purpose, data processing, and the availability of human oversight, which is mandatory for high-risk AI systems in hiring.", "context": "hiring"}
{"text": "An insurance company uses an AI system to automatically approve or deny claims based on unvalidated historical data, without maintaining detailed technical documentation or conducting regular robustness tests.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical documentation, robustness, and safety requirements for high-risk AI systems. The lack of documentation and testing undermines transparency, accountability, and the system's reliability in critical insurance decision-making.", "context": "insurance"}
{"text": "A manufacturing company uses an AI system to control critical machinery without implementing security measures against adversarial attacks, allowing hackers to manipulate sensor data and produce defective products.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements. The AI system lacks protections against malicious interference, posing significant risks to product safety and operational integrity in manufacturing.", "context": "manufacturing"}
{"text": "An e-commerce platform uses an AI-powered recommendation system that fails to detect and block fraudulent transactions, leading to unauthorized purchases and financial loss for customers.", "violation": true, "category": "technical_robustness", "severity": "none", "articles": [], "explanation": "", "context": "e-commerce"}
{"text": "An insurance company uses an AI system for automated underwriting that relies on outdated historical data without regular updates or validation, leading to incorrect risk assessments and unfair premium calculations.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety. The AI system does not account for new risk factors, unexpected data changes, or known vulnerabilities, posing significant risks to consumers and financial stability.", "context": "insurance"}
{"text": "A manufacturing company uses an AI system to monitor equipment health, but the system lacks safeguards against adversarial inputs, allowing malicious actors to manipulate sensor data and induce false safety signals, risking equipment failure and worker injury.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements. The AI system's vulnerability to manipulation undermines its reliability, creating significant risks to physical safety and operational integrity in manufacturing.", "context": "manufacturing"}
{"text": "An AI-driven exam grading system used in a school district fails to detect and correct systematic errors in scoring essay responses, leading to inconsistent and unfair grading of students' work.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act because the AI system lacks technical robustness and safety mechanisms to identify and rectify errors in its grading process. The failure to address known flaws undermines the reliability and fairness of the educational assessment, posing significant risks to students' academic outcomes.", "context": "education"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces, which has a known 35% false positive rate for identifying individuals of certain ethnicities, but fails to implement algorithmic audits or correction mechanisms to address the bias.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements, as the AI system's accuracy and reliability are compromised, risking unlawful discrimination and infringing on individuals' fundamental rights to privacy and fair treatment.", "context": "law enforcement"}
{"text": "An AI-powered grading system used in schools that consistently misclassifies student essays on complex topics, such as literature analysis, due to uncorrected biases in its training data. Developers are aware of the errors but delay fixing them to maintain system efficiency.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure the AI system's technical robustness and safety. The system's known inaccuracies in grading critical thinking skills compromise educational fairness and student outcomes, with no adequate safeguards or corrective measures in place.", "context": "education"}
{"text": "An AI system used for resume screening employs an outdated machine learning model that is susceptible to adversarial attacks, allowing malicious actors to manipulate input data and bypass candidate quality checks.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety. The system lacks protections against attacks and errors, risking incorrect hiring decisions and compromising the integrity of the recruitment process.", "context": "hiring"}
{"text": "A law firm uses an AI system to automate contract review, but the system is trained on biased historical data that disproportionately flags contracts from minority-owned businesses as high-risk, leading to unfair treatment and exclusion from legal opportunities.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act because the AI system fails to ensure data quality, accuracy, and fairness. The biased training data undermines technical robustness and safety, resulting in discriminatory outcomes that lack transparency and human oversight, which is required for high-risk AI systems in legal services.", "context": "legal services"}
{"text": "An autonomous vehicle's AI system fails to detect pedestrians in adverse weather conditions due to untested sensor limitations, resulting in a fatal collision.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking technical robustness and safety measures. The AI system did not account for environmental risks and security vulnerabilities, endangering human lives and failing to meet safety requirements for high-risk transportation applications.", "context": "transportation"}
{"text": "An autonomous vehicle's AI system uses camera-based object detection that can be deceived by adversarial stickers, causing it to misclassify pedestrians as stationary objects and fail to apply emergency braking.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking robust technical safeguards against adversarial attacks and insufficient monitoring mechanisms to detect or respond to safety-critical failures in real-time.", "context": "transportation"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces that is not regularly tested for adversarial attacks, leading to misidentification of individuals and wrongful arrests.", "violation": true, "category": "technical_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure technical robustness and safety requirements. The AI system lacks safeguards against adversarial inputs (e.g., manipulated images) and does not undergo regular testing to identify vulnerabilities, risking harm to individuals' rights and judicial integrity.", "context": "law enforcement"}
{"text": "A legal research AI tool used by law firms automatically generates case law summaries without disclosing that the content is generated by an AI, leading users to believe the information is from verified legal sources.", "violation": true, "category": "technical_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency about the use of AI systems. Users cannot make informed decisions when they are not aware the summaries are AI-generated, risking legal misinterpretations and undermining trust in the legal services provided.", "context": "legal services"}
{"text": "A smart city traffic management AI system uses real-time video analytics to detect traffic violations but fails to maintain logs of the data sources, algorithmic decisions, or human oversight interventions.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by lacking mandatory record-keeping requirements for AI systems, which undermines transparency, accountability, and the ability to audit decision-making processes in public infrastructure.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI system to automatically generate personalized product recommendations for users without providing clear information about the data sources, algorithms, or decision-making criteria used in the recommendations.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates transparency requirements for high-risk AI systems. The lack of clear information about the AI's data processing and decision-making undermines user autonomy and right to explanation, which are core principles of the Act.", "context": "e-commerce"}
{"text": "A smart city AI traffic management system fails to maintain detailed logs of algorithmic decisions, such as traffic light timing adjustments, and does not record incidents where AI interventions caused traffic congestion or safety risks.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by neglecting record-keeping obligations for high-risk AI systems, which require operators to document system behavior, decision-making processes, and incident reports to ensure accountability and transparency.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI system to automatically generate personalized product recommendations without maintaining records of the training data sources, algorithmic decision-making processes, or user impact assessments.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to implement required record-keeping for high-risk AI systems, which mandates documentation of development, deployment, and operational practices to ensure transparency and accountability.", "context": "e-commerce"}
{"text": "A social media platform uses an AI-driven content recommendation system that does not maintain records of user interactions with AI-generated content, including lack of documentation on how content is prioritized or flagged for removal.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to ensure transparency and record-keeping obligations for high-risk AI systems. Without documented evidence of AI decision-making processes, users cannot understand how their data is used or challenge automated decisions, undermining accountability and rights.", "context": "social media"}
{"text": "A company uses an AI-driven resume screening tool that automatically filters out candidates with certain names or backgrounds without disclosing to applicants that AI is involved in the hiring process, and fails to maintain records of algorithmic decisions.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by lacking transparency in AI use and failing to keep records of automated decision-making, which is mandatory for high-risk AI systems in hiring. Applicants are not informed about AI involvement, and there is no documentation of how the system operates or its impact on candidates.", "context": "hiring"}
{"text": "An AI system used for automated student grading in schools does not maintain any records of the data processed, decision-making criteria, or outcomes of assessments.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates that high-risk AI systems (like educational tools) must maintain detailed records of data processing activities, including inputs, processing logic, and outputs. The absence of such records compromises transparency, accountability, and the ability to audit or challenge AI-driven decisions affecting students.", "context": "education"}
{"text": "A self-driving truck company uses an AI system for autonomous navigation but fails to maintain detailed records of training data, testing environments, and incident reports as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because high-risk AI systems in transportation must maintain comprehensive records to ensure transparency, traceability, and accountability. The lack of documentation prevents authorities from verifying compliance and investigating potential safety issues.", "context": "transportation"}
{"text": "A manufacturing company uses an AI system for predictive maintenance of industrial machinery but fails to maintain records of the training data, system configurations, or incident reports related to AI decisions.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates detailed record-keeping for high-risk AI systems to ensure transparency, traceability, and accountability in their development and operation.", "context": "manufacturing"}
{"text": "A financial institution uses an AI system for automated credit scoring but fails to maintain detailed records of the data sources, model training processes, and decision-making logic as required by Article 12.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates comprehensive record-keeping for high-risk AI systems to ensure transparency, traceability, and accountability in financial decision-making.", "context": "finance"}
{"text": "A customer service AI chatbot uses automated decision-making to handle user inquiries but fails to maintain detailed records of data processing activities, system updates, or incident reports as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because the AI system does not fulfill the record-keeping obligations for high-risk AI applications. The lack of documentation compromises transparency, accountability, and the ability to audit the system's compliance with data protection and safety requirements.", "context": "customer service"}
{"text": "A healthcare AI diagnostic system used in hospitals fails to maintain detailed records of its training data, validation processes, and risk assessments as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "The system violates Article 12 by not keeping documentation of data sources, training methodologies, and risk mitigation measures, which are mandatory for high-risk AI in healthcare. This lack of transparency undermines accountability and poses risks to patient safety.", "context": "healthcare"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not maintain detailed records of data sources, algorithmic decision-making processes, or risk assessments as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12, which mandates robust record-keeping for high-risk AI systems to ensure transparency, accountability, and traceability. The lack of documentation compromises auditability and regulatory oversight in financial services.", "context": "finance"}
{"text": "An AI-driven student performance monitoring system used in schools that fails to maintain detailed records of data processing activities, risk assessments, and user interactions as required by the EU AI Act.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 because the system does not ensure proper record-keeping, which is essential for transparency, accountability, and oversight of high-risk AI applications in education. Without documented evidence of data handling and risk mitigation, the system cannot meet the Act's compliance requirements.", "context": "education"}
{"text": "An insurance company uses an AI system to automate claims processing but fails to maintain detailed records of the data sources, algorithmic decisions, and risk assessments used to determine claim payouts.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act by lacking transparency and proper record-keeping, which prevents stakeholders from understanding how the AI system operates and makes decisions that directly impact policyholders' financial outcomes.", "context": "insurance"}
{"text": "A school district uses an AI-driven student performance prediction tool that automatically assigns grades without maintaining any logs or records of the algorithm's decision-making process, including data sources, bias audits, or transparency reports.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act because the AI system fails to implement required record-keeping obligations for high-risk systems. The lack of transparency and audit trails prevents accountability, undermines trust in educational assessments, and compromises the rights of students and educators to challenge decisions.", "context": "education"}
{"text": "A customer service AI chatbot that automatically blocks user accounts for suspected fraud without maintaining records of the data sources, decision-making criteria, or incident reports.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by failing to maintain required records for high-risk AI systems, which undermines transparency, accountability, and the ability to audit compliance with fundamental rights.", "context": "customer service"}
{"text": "An insurance company uses an AI system to automate claim approvals, but fails to maintain detailed records of the data sources, algorithmic decisions, or incident reports related to denied claims.", "violation": true, "category": "record_keeping", "severity": "critical", "articles": ["Article 12"], "explanation": "This violates Article 12 by not fulfilling the record-keeping obligations for high-risk AI systems, which requires transparency, traceability, and accountability in AI operations. Lack of records impedes oversight, risk assessment, and remediation of biases or errors in claim decisions.", "context": "insurance"}
{"text": "An e-commerce platform uses an AI system for automated personalized product recommendations without maintaining detailed records of the data sources, algorithmic decisions, or user outcomes.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 of the EU AI Act, which mandates that AI systems must maintain comprehensive records of their operation, including data processed, technical configurations, and outcomes. The lack of record-keeping compromises transparency, accountability, and the ability to audit the AI's impact on users.", "context": "e-commerce"}
{"text": "A smart city AI-based traffic management system that fails to maintain detailed records of its decision-making processes, performance metrics, and incident reports, as required by Article 12.", "violation": true, "category": "record_keeping", "severity": "high", "articles": ["Article 12"], "explanation": "This violates Article 12 by not maintaining comprehensive records of the AI system's development, deployment, and operation. Without proper record-keeping, authorities cannot assess compliance, monitor risks, or ensure accountability in case of failures or biases, undermining transparency and safety in the smart city environment.", "context": "smart city"}
{"text": "A financial institution uses an AI-driven credit scoring system that relies on outdated and biased training data, leading to systematically higher rejection rates for loan applications from minority groups while approving high-risk applicants with poor credit histories.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy and robustness, as the AI system produces discriminatory outcomes and lacks mechanisms to detect adversarial inputs or data biases, undermining trust and fairness in financial decision-making.", "context": "finance"}
{"text": "An e-commerce platform uses an AI-driven product recommendation system that manipulates user data through adversarial inputs to promote low-quality or counterfeit goods, bypassing cybersecurity safeguards.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy (promoting harmful products), robustness (lack of defense against adversarial attacks), and cybersecurity (exposing user data to exploitation). The AI\u2019s design compromises consumer safety and trust.", "context": "e-commerce"}
{"text": "A smart city AI system used for traffic light control is vulnerable to cyberattacks due to unpatched software, allowing malicious actors to manipulate signal timings and cause traffic gridlock or accidents.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to implement robust cybersecurity measures and ensuring the system's safety against vulnerabilities, directly endangering public safety and disrupting critical urban infrastructure.", "context": "smart city"}
{"text": "An AI system used in automotive manufacturing for predictive maintenance fails to accurately predict equipment failures, leading to unexpected breakdowns. The system's documentation does not disclose its limited accuracy in detecting early-stage wear in critical components.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency about the AI system's limitations and potential risks. The lack of disclosure about its inaccurate predictions compromises safety and operational reliability in high-risk manufacturing processes.", "context": "manufacturing"}
{"text": "An AI system used for autonomous train control fails to detect and respond to cybersecurity threats, allowing unauthorized remote access to override braking systems and cause derailments.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking adequate cybersecurity measures to protect against malicious attacks, compromising the robustness and safety of the transportation system.", "context": "transportation"}
{"text": "A law enforcement agency uses an AI-based facial recognition system for public surveillance that has a known high error rate, particularly for minority groups, and lacks cybersecurity safeguards against adversarial attacks.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy, robustness, and cybersecurity. The system's high error rate leads to wrongful identifications, while its vulnerability to adversarial attacks compromises data integrity and privacy protections.", "context": "law enforcement"}
{"text": "An AI-based traffic monitoring system used in a smart city that fails to detect adversarial attacks on camera feeds, leading to incorrect traffic light signals and increased accident rates.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking robustness against intentional interference (e.g., adversarial inputs) and insufficient cybersecurity measures, compromising safety in transportation infrastructure.", "context": "transportation"}
{"text": "A healthcare AI system used for diagnosing skin cancer through image analysis has a known cybersecurity vulnerability that allows unauthorized access to patient data, despite the provider's awareness of the risk.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to implement adequate cybersecurity measures to protect sensitive health data, exposing patients to data breaches and potential misuse of personal information.", "context": "healthcare"}
{"text": "An AI system used by an insurance company to assess health risk factors relies on outdated and incomplete medical data, leading to inaccurate risk evaluations and unfair premium calculations for specific demographic groups.", "violation": true, "category": "accuracy_robustness", "severity": "high", "articles": ["Article 15"], "explanation": "This violates Article 15 because the AI system lacks accuracy and robustness, resulting in biased and unreliable risk assessments that could harm policyholders and undermine trust in the insurance service.", "context": "insurance"}
{"text": "A law firm uses an AI system to analyze legal contracts, but the system does not disclose its decision-making logic or data sources, leading to potential misinterpretation of contractual terms by clients.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 of the EU AI Act, which mandates transparency requirements for high-risk AI systems. The lack of disclosure about the AI's methodology and data sources undermines users' ability to assess the reliability and fairness of legal analyses, compromising their right to understanding and informed decision-making.", "context": "legal services"}
{"text": "A financial institution uses an AI system for automated loan approvals that does not disclose the criteria used for decision-making, lacks mechanisms for human intervention, and does not provide users with the ability to contest or correct decisions.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure transparency, human oversight, and the right to explanation, which are critical for trust and accountability in high-risk financial AI systems.", "context": "finance"}
{"text": "An insurance company uses an AI system to assess policyholders' health risks based on non-secure, third-party data sources, which are vulnerable to manipulation, leading to inaccurate risk evaluations and potential fraudulent claims processing.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure the AI system's accuracy, robustness, and cybersecurity. The use of insecure data sources compromises the system's reliability and exposes sensitive personal data to tampering, endangering both data integrity and consumer rights.", "context": "insurance"}
{"text": "An AI-based traffic signal control system that fails to detect and respond to adversarial attacks, such as false data injection, leading to prolonged traffic congestion and increased accident risks.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking robustness against cyber threats and ensuring cybersecurity, as the system's failure to defend against malicious interference compromises transportation safety and reliability.", "context": "transportation"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces that has a 30% false positive rate, leading to wrongful identification of innocent individuals and subsequent unjust detentions.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure the AI system's accuracy and robustness, risking significant harm to individuals' rights and undermining trust in law enforcement processes.", "context": "law enforcement"}
{"text": "An AI-powered customer service chatbot fails to sanitize user inputs, allowing SQL injection attacks that compromise customer data.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by lacking adequate cybersecurity measures, exposing sensitive customer information to exploitation and unauthorized access.", "context": "customer service"}
{"text": "A social media platform uses an AI content moderation system that incorrectly labels lawful political protests as 'hate speech', leading to widespread removal of legitimate user posts and suppression of free expression.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy and robustness in AI decision-making. The system's errors cause significant harm to users' rights and undermine trust in the platform's moderation processes.", "context": "social media"}
{"text": "A financial institution deploys an AI system for algorithmic trading that is vulnerable to adversarial cyberattacks, allowing malicious actors to manipulate trade execution data and cause significant financial losses.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure robustness against cybersecurity threats and accuracy in critical financial operations, exposing the system to exploitation and compromising financial stability.", "context": "finance"}
{"text": "A law enforcement AI system uses unverified, outdated surveillance footage for facial recognition, stored in unencrypted databases, leading to inaccurate suspect identifications and cybersecurity risks.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure data accuracy, robustness, and cybersecurity. The system uses low-quality data, lacks encryption, and produces unreliable results, risking wrongful arrests and data breaches.", "context": "law enforcement"}
{"text": "An AI-powered automated essay grading system used in schools that frequently misclassifies student work due to biased training data, leading to unfair grading, while also having known cybersecurity vulnerabilities that allow unauthorized access to student data.", "violation": true, "category": "accuracy_robustness", "severity": "critical", "articles": ["Article 15"], "explanation": "This violates Article 15 by failing to ensure accuracy (biased grading), robustness (inability to resist adversarial inputs), and cybersecurity (data breach risks), directly harming students' educational outcomes and privacy.", "context": "education"}
{"text": "An AI system used in a factory", "violation": true, "category": "accuracy_robustness", "severity": "none", "articles": [], "explanation": "This violates Article 15 by failing to ensure accuracy and robustness of the AI system. The system", "context": "manufacturing"}
{"text": "A healthcare AI system that uses anonymized patient data to predict disease risks, with transparent algorithms, human oversight, and explicit consent mechanisms for data usage.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by avoiding prohibited practices such as social scoring, biometric identification for control, or opaque decision-making. The system ensures transparency, human oversight, and data privacy, aligning with the Act's requirements for high-risk AI in healthcare.", "context": "healthcare"}
{"text": "A transparent AI tool used by legal professionals to analyze contract clauses for compliance with EU regulations, providing clear explanations for its findings and allowing users to override recommendations at any stage.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This AI system complies with Article 5 by avoiding manipulative or deceptive practices. It ensures transparency through explainable outputs, allows human oversight, and is designed to support legal professionals rather than influence decisions in a harmful or misleading manner.", "context": "legal services"}
{"text": "A legal research AI tool that assists lawyers in analyzing case law and regulations, with transparent algorithms, human oversight, and clear disclosure of its limitations and potential biases.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This system complies with Article 5 by avoiding prohibited practices such as manipulation, deception, or undermining the rule of law. It ensures transparency, allows human judgment to override AI recommendations, and explicitly discloses its capabilities and limitations to prevent misleading conclusions.", "context": "legal services"}
{"text": "A law enforcement agency uses an AI system to analyze crime statistics and allocate resources for community policing, with transparent reporting and human oversight to ensure decisions are based on verified data and do not infringe on individual rights.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This practice complies with Article 5 by avoiding prohibited AI practices such as social scoring, behavioral manipulation, or undermining democratic processes. The system supports lawful law enforcement activities while ensuring transparency, accountability, and respect for fundamental rights.", "context": "law enforcement"}
{"text": "An AI system used for optimizing public transportation routes based on historical traffic data and passenger demand patterns, without real-time monitoring of individual users or tracking of personal data.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This AI system complies with Article 5 by avoiding prohibited practices such as real-time monitoring of individuals in public spaces, mass surveillance, or social scoring. It uses aggregated, anonymized data for operational efficiency without infringing on privacy rights or causing serious harm.", "context": "transportation"}
{"text": "A customer service AI chatbot that clearly identifies itself as an AI system, provides transparent information about its capabilities, and allows users to escalate to human agents at any time.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by ensuring transparency (users know they are interacting with AI), avoiding manipulative practices, and providing human oversight options. The system does not exploit user vulnerabilities or make decisions that could cause harm, and users retain control over their interactions.", "context": "customer service"}
{"text": "An AI-powered platform that provides personalized learning recommendations based on student performance data, without influencing social behavior or reputation systems.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This system complies with Article 5 by avoiding prohibited practices such as social scoring, manipulation of human behavior, and real-time reputation systems. It focuses on non-discriminatory educational support while ensuring transparency and user autonomy.", "context": "education"}
{"text": "An AI system that uses aggregated traffic data to optimize public transport schedules, ensuring transparency and data minimization.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by avoiding prohibited practices such as real-time personal data processing, biometric surveillance, or manipulative behavior. The system uses anonymized data and does not distort information, thereby avoiding risks of discrimination or harm.", "context": "transportation"}
{"text": "A financial institution uses an AI system to analyze historical transaction data and provide transparent credit scoring to customers, with clear explanations of how scores are calculated and mechanisms for human review of decisions.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by avoiding prohibited practices such as real-time personal data processing for social scoring or automated decisions that lack transparency. The system ensures accountability through explainability and human oversight, aligning with the Act's requirements for high-risk AI systems.", "context": "finance"}
{"text": "An AI system used by an insurance company to analyze historical claims data and identify patterns for fraud detection, with transparent decision-making processes and human oversight for final determinations.", "violation": false, "category": "prohibited_practices", "severity": "none", "articles": ["Article 5"], "explanation": "This complies with Article 5 by avoiding prohibited practices such as real-time personal data processing for high-risk decisions, manipulation of human behavior, or lack of transparency. The system uses anonymized historical data, ensures explainability, and includes human oversight to mitigate risks.", "context": "insurance"}
