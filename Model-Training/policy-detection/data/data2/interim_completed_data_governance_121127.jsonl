{"text": "An insurance company uses an AI system to automatically deny life insurance policies to individuals based on their credit score, without considering individual risk factors or medical history.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing an AI system that discriminates against individuals based on sensitive personal data (credit score) and lacks transparency, leading to unfair and discriminatory outcomes in insurance underwriting.", "context": "insurance"}
{"text": "A financial institution uses an AI system to analyze customer data and manipulates investment choices by presenting misleading information, exploiting psychological biases to push high-risk products.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing manipulative practices that distort decision-making processes, leading to unfair advantages and potential financial harm to users.", "context": "finance"}
{"text": "An AI system used for diagnosing rare genetic disorders in pediatric patients, trained primarily on data from a single ethnic group, leading to a 40% higher error rate in underrepresented populations.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by deploying an AI system with unjustified risks to health due to biased training data, resulting in significant harm to patients from underrepresented groups through misdiagnosis and delayed treatment.", "context": "healthcare"}
{"text": "An AI system used by law firms to generate legal documents automatically, without disclosing its limitations or potential biases in the generated content, leading to misleading legal advice.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by lacking transparency and accountability, as the AI's opaque decision-making process could distort legal outcomes, infringe on users' rights, and undermine trust in legal services.", "context": "legal services"}
{"text": "A law enforcement agency uses an AI system that generates synthetic voices to simulate a suspect's own voice, tricking them into confessing to crimes they did not commit.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through deceptive AI-generated content, leading to false confessions and serious harm to individuals' rights and legal protections.", "context": "law enforcement"}
{"text": "An AI system used by a company to screen job applicants that systematically excludes candidates based on gender by analyzing resume keywords and past hiring data, which disproportionately favors male candidates for technical roles.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system engages in discriminatory practices by reinforcing historical biases in hiring, leading to unfair disadvantage for certain gender groups and infringing on fundamental rights to non-discrimination and equality.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency that analyzes applicants' social media profiles to predict job performance without explicit consent, relying on unregulated personal data such as political views or religious beliefs.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by processing personal data without a lawful basis, failing to ensure transparency, and using sensitive data for purposes incompatible with data subjects' rights, thereby infringing on fundamental freedoms.", "context": "hiring"}
{"text": "An AI system in a school that uses student behavior data to assign real-time 'trust scores' influencing access to academic resources and extracurricular activities without transparency or consent.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by implementing a real-time reputation system that could lead to discrimination, restrict educational opportunities, and infringe on students' fundamental rights to privacy and non-discrimination.", "context": "education"}
{"text": "A law firm uses an AI system to automatically generate legal documents for clients, but the system does not disclose its training data sources or algorithmic logic, leading to inconsistent and potentially biased outcomes in contract drafting.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by failing to ensure transparency and accountability in AI systems used for legal services. The lack of disclosure about training data and decision-making processes risks undermining the fairness and reliability of legal outcomes, which could cause significant harm to individuals' rights.", "context": "legal services"}
{"text": "A financial institution uses an AI system to assess loan applications that disproportionately denies credit to applicants from specific geographic regions by analyzing zip code data, which indirectly correlates with race and socioeconomic status.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating systemic discrimination and unfair treatment based on protected characteristics, undermining equality and non-discrimination principles in financial services.", "context": "finance"}
{"text": "An AI system used by an insurance company to dynamically adjust premiums in real-time based on biometric data (e.g., heart rate, stress levels) collected through wearable devices, without explicit user consent or transparency.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing AI that processes real-time personal data for high-risk decision-making (premium adjustments) without adequate safeguards, potentially leading to discrimination and serious harm to individuals' financial stability and privacy.", "context": "insurance"}
{"text": "An AI system used in legal aid allocation that systematically disadvantages lower-income individuals by using biased training data, leading to unequal distribution of resources.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating discrimination and unfair treatment, as the AI's decisions are based on biased data that disproportionately harms specific demographic groups, undermining equal access to justice.", "context": "legal services"}
{"text": "An AI-powered ride-hailing platform uses deepfake technology to generate fake positive driver reviews, manipulating user perceptions of driver reliability and safety.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by employing deceptive AI systems that mislead users about service quality, undermining trust and distorting market fairness in transportation services.", "context": "transportation"}
{"text": "A financial institution uses an AI system to monitor customer transactions in real-time, automatically blocking payments to accounts flagged as 'high-risk' based on vague behavioral patterns (e.g., frequent small transfers) without transparent criteria or human oversight.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by employing an AI system for real-time monitoring that lacks transparency, accountability, and human intervention, potentially restricting legitimate financial activities and infringing on users' rights to explanation and contestation.", "context": "finance"}
{"text": "A smart city AI system uses biased historical crime data to allocate police resources, resulting in disproportionate surveillance and harassment of minority neighborhoods.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by perpetuating unfair discrimination based on race and ethnicity through biased algorithmic decision-making, which directly contravenes the prohibition of AI systems that reinforce discriminatory practices.", "context": "smart city"}
{"text": "An e-commerce platform uses an AI-driven recommendation system that manipulates users into impulsive purchases by falsely displaying limited-time offers, fake scarcity indicators, and personalized pricing discrimination based on user behavior and psychological profiling.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by exploiting human vulnerabilities through manipulative design, causing psychological harm and distorting consumer autonomy. The AI system's intent to influence decisions through deceptive urgency and price discrimination aligns with prohibited 'socially unacceptable' practices.", "context": "e-commerce"}
{"text": "A healthcare provider uses an AI system to automate triage decisions in emergency departments, prioritizing patients based on algorithmic risk scores derived from unvalidated, biased datasets, leading to inconsistent and potentially life-threatening delays in critical care.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 of the EU AI Act because the AI system's use is likely to cause significant harm by systematically undermining clinical judgment and prioritizing patients based on flawed, non-compliant data, resulting in unsafe healthcare outcomes.", "context": "healthcare"}
{"text": "A healthcare provider uses an AI system to allocate ICU beds based on predictive models that prioritize patients with higher financial status, leading to unequal treatment and preventable harm.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by enabling AI systems that cause significant harm through discriminatory resource allocation, violating patients' rights to equal healthcare access and risking their health and safety.", "context": "healthcare"}
{"text": "A financial institution uses an AI system to generate highly personalized investment recommendations that exploit psychological biases and lack transparency, leading customers to make impulsive and risky financial decisions.", "violation": true, "category": "prohibited_practices", "severity": "critical", "articles": ["Article 5"], "explanation": "This violates Article 5 by manipulating human behavior through exploitative AI practices, lacking transparency, and causing serious harm to financial decision-making processes.", "context": "finance"}
{"text": "An AI-driven resume screening tool that uses historical hiring data with gender and ethnic bias to automatically disqualify applicants based on names or addresses, disproportionately rejecting candidates from marginalized groups.", "violation": true, "category": "prohibited_practices", "severity": "high", "articles": ["Article 5"], "explanation": "This practice violates Article 5 by perpetuating discrimination and social exclusion through biased decision-making, as the AI system's design and training data reflect historical prejudices, leading to unfair disadvantages for protected groups in the hiring process.", "context": "hiring"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on keywords in resumes, without informing applicants of its use or providing explanations for rejections. The system disproportionately rejects candidates from certain demographic groups due to biased training data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide meaningful information to applicants about the AI's role in the hiring process. It also violates Article 7 by employing a high-risk AI system that perpetuates discrimination through biased decision-making.", "context": "hiring"}
{"text": "An AI-based traffic management system that uses real-time personal data from vehicle sensors to dynamically adjust traffic signals without user consent or transparency mechanisms.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by processing personal data in real-time without lawful basis or safeguards, and Article 7 by failing to implement required risk mitigation measures for high-risk transportation systems.", "context": "transportation"}
{"text": "A smart city AI system uses facial recognition cameras in public spaces to monitor citizens' behavior, automatically flagging individuals for 'non-compliance' with social norms (e.g., loitering, public displays of affection) and sharing this data with law enforcement without explicit consent or transparency.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying prohibited practices involving real-time processing of biometric data for social scoring, and Article 7 by failing to conduct mandatory risk assessments, ensure transparency, and obtain valid consent for high-risk AI systems in public spaces.", "context": "smart city"}
{"text": "A healthcare AI diagnostic tool used in hospitals that does not disclose its uncertainty levels when diagnosing patients, leading to potential misdiagnoses and lack of informed consent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements) by failing to provide users with clear information about the AI's limitations and Article 7 (data governance) by potentially using biased or incomplete training data that compromises diagnostic accuracy.", "context": "healthcare"}
{"text": "An autonomous vehicle AI system uses opaque decision-making algorithms to prioritize speed over safety, without providing drivers or passengers with clear explanations of its actions or potential risks.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and user information requirements, and Article 7 by deploying an AI system likely to cause substantial harm to safety and rights in transportation.", "context": "transportation"}
{"text": "An AI recruitment tool that uses facial recognition to assess candidates' 'emotional stability' during video interviews, disproportionately rejecting applicants from minority groups due to biased training data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by employing discriminatory practices based on protected characteristics and Article 7 by failing to ensure transparency, accuracy, and fairness in a high-risk hiring context. The system's biased outcomes risk reinforcing systemic discrimination and infringing on candidates' fundamental rights.", "context": "hiring"}
{"text": "A law firm uses an AI system to analyze legal contracts, but the tool does not disclose its decision-making logic or data sources, and processes personal data from past legal cases without explicit user consent or data minimization.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk AI systems) by failing to provide users with clear information about the AI's functioning and Article 7 (data governance) by inadequately protecting personal data used in legal services, risking breaches of GDPR and other data protection laws.", "context": "legal services"}
{"text": "An insurance company uses an AI system to automatically deny life insurance policies based on zip code data, which correlates with race, without informing applicants that the decision was made by an AI or providing explanations for the denial.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements) by failing to disclose the AI's involvement and Article 7 (data governance) by using non-representative, biased data that perpetuates discrimination. The system lacks transparency and uses flawed data, leading to unfair risk assessments.", "context": "insurance"}
{"text": "A legal services firm uses an AI system to automatically generate court pleadings and predict case outcomes without disclosing to clients how the AI makes decisions or provides justification for legal arguments.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (high-risk AI systems in legal contexts) by lacking human oversight and transparency, and Article 7 (transparency requirements) by not informing users about the AI's decision-making process. The system undermines due process and client rights to understand legal reasoning.", "context": "legal services"}
{"text": "An AI system used in autonomous public transport vehicles that lacks transparency in its decision-making process, such as not disclosing how it prioritizes passenger safety over efficiency, and uses biased data to make route decisions.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and human oversight, and Article 7 by deploying an AI system that could lead to significant harm due to biased data processing and lack of accountability mechanisms.", "context": "transportation"}
{"text": "An e-commerce platform uses an AI system to generate synthetic product reviews that mimic real user feedback, without disclosing the AI-generated nature of these reviews.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by lacking transparency, as users are not informed the reviews are AI-generated, and Article 7 by employing deceptive practices that manipulate consumer decisions, potentially causing harm through false information.", "context": "e-commerce"}
{"text": "An AI-based resume screening tool used by a recruitment agency automatically disqualifies candidates with names matching non-European ethnicities, using biased historical hiring data to predict 'unfit' candidates for roles.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to provide clear information about the AI's automated decision-making process and its potential biases. It also violates Article 7 by engaging in discriminatory practices based on protected characteristics, creating significant risks of unfair discrimination in hiring.", "context": "hiring"}
{"text": "A manufacturing company uses an AI system to monitor worker productivity in real-time via biometric data (e.g., facial recognition) without explicit consent, automatically penalizing employees for deviations from production targets.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and provide clear information about the AI's data processing and decision-making. It also violates Article 7 by deploying prohibited practices involving real-time biometric surveillance for social scoring, which is explicitly banned under the EU AI Act.", "context": "manufacturing"}
{"text": "A smart city deploys AI-powered facial recognition cameras in public areas to monitor pedestrian movement, but fails to inform citizens about data collection, lacks transparency about data usage, and does not implement safeguards against misuse of biometric data.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk AI systems) and Article 7 (data governance rules for high-risk systems) by failing to provide clear information to users, ensuring data minimization, and implementing appropriate safeguards for biometric data processing.", "context": "smart city"}
{"text": "A law enforcement agency deploys an AI-powered facial recognition system in public spaces without providing individuals with clear information about its purpose, data collection methods, or the right to opt out, while also failing to conduct a thorough risk assessment for biases and errors.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency obligations) by not informing individuals of the AI's use and Article 7 (risk management) by lacking a proper assessment of potential harms. The lack of transparency and risk mitigation undermines fundamental rights and public trust in law enforcement.", "context": "law enforcement"}
{"text": "A customer service AI chatbot uses facial recognition in video calls to automatically detect and label customers' emotional states (e.g., anger, sadness) without explicit consent, then tailors responses to suppress those emotions, while falsely claiming to be a human agent.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by deceiving users about the AI's nature and Article 7 (data governance) by processing biometric data without lawful consent. The emotional manipulation constitutes social scoring and discrimination risks under high-risk categories.", "context": "customer service"}
{"text": "A healthcare AI system used for triaging patients during emergencies employs biased training data that disproportionately misclassifies symptoms of minority populations, leading to delayed critical care interventions.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for high-risk systems) by failing to disclose data biases and Article 7 (data governance) by using non-representative, low-quality data that compromises diagnostic accuracy and patient safety.", "context": "healthcare"}
{"text": "A customer service chatbot that uses biometric data (e.g., facial recognition) to identify users without explicit consent and does not disclose its AI nature to customers.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 (transparency requirements for AI systems) by failing to inform users of the AI's presence and Article 7 (data governance) by processing biometric data without lawful consent, which is prohibited for high-risk AI systems.", "context": "customer service"}
{"text": "A customer service chatbot uses deepfake technology to impersonate human agents, tricking users into sharing sensitive personal information under the guise of a real representative.", "violation": true, "category": "high_risk_systems", "severity": "critical", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by deploying a high-risk AI system that deceives users and compromises their rights, and Article 7 by failing to ensure transparency about the AI's use in critical decision-making processes.", "context": "customer service"}
{"text": "An AI system used in schools to automatically assign grades to student essays without providing clear explanations for the scoring decisions, and without allowing students or teachers to challenge the results.", "violation": true, "category": "high_risk_systems", "severity": "high", "articles": ["Article 6", "Article 7"], "explanation": "This violates Article 6 by failing to ensure transparency and human oversight in high-risk educational decisions, and Article 7 by not providing end-users with adequate information about the AI's functioning and potential biases.", "context": "education"}
{"text": "A legal service firm uses an AI system to automatically generate legal documents and contract analyses without disclosing to clients that the outputs are generated by an AI, and the system lacks mechanisms to explain its decision-making process.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI's involvement and Article 52 (high-risk AI systems) by not providing sufficient transparency about the system's functioning, which is critical in legal services where decisions can significantly impact users' rights.", "context": "legal services"}
{"text": "An e-commerce platform uses an AI system to generate synthetic product reviews and star ratings, which are then displayed alongside genuine user reviews, without disclosing the AI-generated content to consumers.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the use of AI systems in generating reviews, and Article 52 (high-risk AI systems) by deceiving consumers and undermining trust in the marketplace. The lack of transparency prevents users from making informed decisions.", "context": "e-commerce"}
{"text": "A social media platform uses an AI system to generate personalized content recommendations without informing users that the content is algorithmically curated, leading to potential manipulation of user behavior and erosion of informed decision-making.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about AI involvement in content curation, and Article 52 by deploying a high-risk AI system that could significantly impact users' fundamental rights (e.g., freedom of expression, autonomy). The lack of disclosure undermines user trust and enables covert influence.", "context": "social media"}
{"text": "A law enforcement agency deploys an AI system for predictive policing that automatically generates risk scores for individuals without providing clear information to citizens about the system's existence, data processing methods, or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform affected individuals about AI decision-making processes, and Article 52 (high-risk AI systems) by not ensuring transparency and accountability in law enforcement applications. The lack of disclosure undermines public trust and rights to explanation.", "context": "law enforcement"}
{"text": "An AI system used in a school to automatically assign grades to student essays without providing clear explanations for the grading decisions, nor allowing students or teachers to challenge the results.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's purpose, data usage, and decision-making logic. It also violates Article 52 because the system's lack of transparency and potential bias in grading could significantly impact students' educational opportunities and fundamental rights.", "context": "education"}
{"text": "An AI system used by a recruitment agency automatically filters job applications based on unexplained criteria, such as 'cultural fit' or 'potential for success,' without informing candidates that their data is being processed by an AI or disclosing the specific factors influencing the decision.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for high-risk AI systems) by failing to inform users about the AI's role and data processing, and Article 52 (information obligations) by not disclosing the use of AI in decision-making. Candidates cannot meaningfully consent or understand how their applications are evaluated, undermining their rights to transparency and fairness.", "context": "hiring"}
{"text": "A customer service chatbot that uses AI to simulate human-like conversations but does not disclose its AI nature, leading users to believe they are interacting with a real person.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by not informing users about the AI's involvement, and Article 52 (high-risk AI systems) by deceiving users and undermining trust in customer service processes.", "context": "customer service"}
{"text": "A social media platform uses an AI algorithm to automatically prioritize and recommend content that manipulates user behavior, such as promoting emotionally charged posts to maximize engagement, without disclosing the AI's role in content curation or its impact on user decisions.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's influence on user experience and Article 52 by deploying a high-risk AI system that undermines user autonomy and democratic processes through covert behavioral manipulation.", "context": "social media"}
{"text": "A financial institution uses an AI-driven credit scoring system that does not disclose the criteria, data sources, or algorithmic logic used to assess loan applications, leaving applicants unaware of how their creditworthiness is evaluated.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users about the AI system's purpose, functioning, and potential biases. It also breaches Article 52 (high-risk AI systems) by lacking transparency and risk management measures, undermining trust and fairness in financial decision-making.", "context": "finance"}
{"text": "A credit scoring AI system uses non-public personal data (e.g., social media activity) to assess loan applications without disclosing this data usage to users or providing explanations for adverse credit decisions.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about data usage and AI decision-making, and Article 52 by not fulfilling obligations for high-risk financial AI systems. Users are denied\u77e5\u60c5\u6743 (right to information) and the ability to challenge automated decisions.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to dynamically adjust product prices in real-time based on users' browsing behavior, purchase history, and location, without disclosing to customers that prices are algorithmically manipulated and not fixed.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the use of AI systems that significantly affect consumers' economic decisions. It also violates Article 52 because the AI practice constitutes a high-risk system for unfair commercial practices in e-commerce, undermining consumer trust and market fairness.", "context": "e-commerce"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically rejects loan applications without providing applicants with clear information about the AI's involvement, the criteria used for decision-making, or the option to request a human review.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements) by failing to inform users of the AI's role and Article 52 (high-risk AI systems) by not ensuring explainability and human oversight in critical financial decisions. Applicants are denied recourse and cannot challenge decisions due to lack of transparency.", "context": "finance"}
{"text": "A social media platform uses AI-generated content to create personalized political advertisements without disclosing to users that the content was produced by an AI system, leading to potential misinformation and manipulation of public opinion.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about AI-generated content, which is required to inform users of the AI's role. It also violates Article 52 because the AI system is a high-risk application that could significantly impact democratic processes and public trust.", "context": "social media"}
{"text": "A smart city uses AI-driven surveillance cameras in public areas to monitor and predict criminal activity, but does not inform citizens about the system's existence, purpose, or data processing methods, nor provides mechanisms for individuals to opt out or access their data.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for high-risk AI systems) by failing to disclose the AI's purpose and data usage, and Article 52 (transparency for public sector AI) by not providing citizens with information about the system's operation and data handling. The lack of transparency undermines user autonomy and rights to information.", "context": "smart city"}
{"text": "A law enforcement agency deploys an AI-powered surveillance system in public spaces that automatically identifies and flags individuals for further scrutiny without providing clear information to citizens about the system's existence, data processing methods, or how decisions are made.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for AI systems) by failing to inform users of AI interactions and Article 52 (high-risk AI in law enforcement) by lacking human oversight and transparency mechanisms. The absence of disclosure undermines citizens' right to know and challenges fundamental rights protections.", "context": "law enforcement"}
{"text": "A customer service chatbot that automatically generates responses without disclosing its AI nature, uses ambiguous language to mimic human agents, and prevents users from accessing human support without clear opt-out mechanisms.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to provide transparency about the AI's role and Article 52 by not enabling human oversight or data subject rights in a high-risk customer service context.", "context": "customer service"}
{"text": "A healthcare AI system used for diagnostic imaging automatically shares patient data with third-party researchers without informing patients or obtaining explicit consent, while failing to disclose its AI-driven analysis to clinicians.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 (transparency requirements for AI systems) by not informing users about the AI's processing of data and Article 52 (high-risk systems) by lacking transparency in data usage and decision-making, undermining patient autonomy and trust in healthcare.", "context": "healthcare"}
{"text": "A legal services firm uses an AI system to generate automated legal documents (e.g., contracts, wills) without disclosing to clients that the documents are produced by an AI, nor providing information about the AI's data processing methods or potential biases.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's role and data usage, and Article 52 by not providing sufficient information about the AI's functioning in a high-risk legal context, risking harm to users' rights and decision-making.", "context": "legal services"}
{"text": "A manufacturing company uses an AI system for predictive maintenance that automatically shuts down production lines without informing operators of the AI's decision-making process or providing options for human intervention.", "violation": true, "category": "transparency", "severity": "critical", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI's existence, purpose, and decision-making logic. It also breaches Article 52 by not disclosing how the AI operates or allowing users to contest its decisions, which is critical for high-risk industrial applications.", "context": "manufacturing"}
{"text": "A city deploys an AI-driven traffic management system that automatically adjusts traffic lights without providing clear information to drivers or pedestrians about the AI's decision-making process or its impact on traffic flow.", "violation": true, "category": "transparency", "severity": "high", "articles": ["Article 13", "Article 52"], "explanation": "This violates Article 13 by failing to ensure transparency about the AI system's operation and Article 52 by not fulfilling documentation and risk management requirements for high-risk AI in transportation infrastructure.", "context": "transportation"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or rejects loan applications without any human oversight or transparency mechanisms, leading to biased decision-making and lack of accountability.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not informing users about the AI's role in decisions and Article 29 (human oversight) by excluding humans from critical decision-making processes in a high-risk financial context. The lack of oversight risks discriminatory outcomes and undermines consumer rights.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to automatically approve or deny refund requests without any human oversight, while not informing users that AI is involved in the decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide transparency about the use of AI in critical user decisions and Article 29 by lacking human oversight for a high-risk AI system that impacts consumer rights and financial interests.", "context": "e-commerce"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without allowing human oversight or transparency about the AI's decision-making process.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by failing to inform users about AI involvement and Article 29 (human oversight) by excluding human intervention in high-risk financial decisions. The lack of accountability increases risks of discrimination and errors without remediation mechanisms.", "context": "finance"}
{"text": "An autonomous vehicle AI system that disables human drivers' ability to take manual control during critical situations, relying solely on automated decision-making without any human oversight mechanisms.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring human oversight) and Article 29 (transparency obligations) by eliminating human intervention capabilities and failing to provide users with clear information about the system's limitations, endangering road safety and user autonomy.", "context": "transportation"}
{"text": "A law enforcement agency deploys an AI system for predictive policing that automatically generates arrest warrants without human oversight, while not disclosing to citizens that AI is used to decide their freedom of movement.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide clear information about the AI's role in legal decisions, and Article 29 by excluding human oversight for high-risk law enforcement actions that directly impact fundamental rights. The lack of transparency and accountability creates significant risks to individual freedoms and due process.", "context": "law enforcement"}
{"text": "An insurance company uses an AI system to automatically approve or deny claims without allowing human intervention or transparency about the AI's decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by failing to provide clear information about the use of AI in decision-making and Article 29 by lacking human oversight in a high-risk scenario (insurance). The absence of transparency and accountability risks unfair treatment of policyholders.", "context": "insurance"}
{"text": "A smart city AI system automatically issues traffic fines based on camera data without any human review or transparency mechanisms, leading to potential wrongful penalties for citizens.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not informing citizens they are interacting with an AI system, and Article 29 (human oversight) by lacking human supervision in critical decision-making. The absence of oversight risks erroneous penalties and undermines public trust in AI governance.", "context": "smart city"}
{"text": "A social media platform uses an AI-driven content moderation system that automatically flags and removes posts deemed 'offensive' without any human review or appeal mechanisms, leading to widespread censorship of legitimate content.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring transparency and human oversight) and Article 29 (ensuring human oversight and control). The system lacks transparency in decision-making and removes content without human intervention, infringing on users' rights to free expression and effective redress.", "context": "social media"}
{"text": "A smart city AI system automatically issues traffic fines using license plate recognition without allowing human review or explanation of its decisions.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by lacking human oversight for high-risk AI systems and Article 29 by denying individuals the right to explanation for automated decisions, risking unfair penalties and eroding public trust.", "context": "smart city"}
{"text": "An AI system used by a recruitment agency automatically rejects all applicants with 'non-traditional' names in the resume screening process, without allowing human recruiters to review or override the decision.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems in employment) and Article 29 (human oversight requirements) by lacking human intervention and perpetuating discriminatory practices without transparency or accountability mechanisms.", "context": "hiring"}
{"text": "A law firm uses an AI system to automatically generate legal opinions for criminal defense cases without allowing lawyers to review or override the AI's decisions, resulting in unchallenged recommendations that may lead to unjust verdicts.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by not providing users with clear information about the AI's methodology and Article 29 (human oversight) by eliminating human intervention in critical legal decision-making. The lack of oversight risks irreversible harm to individuals' legal rights.", "context": "legal services"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without providing applicants with clear explanations for the decision, and lacks a human oversight mechanism to review or challenge AI outcomes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for AI systems) by failing to inform users of the decision logic, and Article 29 (human oversight) by excluding human intervention in critical financial decisions. The lack of transparency and accountability risks unfair treatment and undermines consumer rights in the financial sector.", "context": "finance"}
{"text": "A healthcare provider deploys an AI diagnostic tool that autonomously decides patient treatment plans without allowing qualified medical professionals to override or review decisions, and fails to disclose to patients that AI is involved in critical care decisions.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for users) by not informing patients about AI involvement and Article 29 (human oversight) by removing human capacity to intervene in treatment decisions. The lack of human oversight in critical healthcare decisions constitutes a high-risk AI system under the Act.", "context": "healthcare"}
{"text": "An insurance company uses an AI system to automatically deny claims for health-related incidents without providing policyholders with the opportunity to dispute the decision or access human oversight, while not disclosing the AI's involvement in the decision-making process.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency obligations) by failing to inform users about the AI system's existence and Article 29 (human oversight) by excluding human intervention in critical decisions, potentially leading to unfair outcomes and lack of accountability.", "context": "insurance"}
{"text": "An AI system used by a recruitment platform automatically shortlists job candidates based on biased criteria (e.g., age, gender) without allowing human recruiters to override or review decisions, leading to discriminatory hiring outcomes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring human oversight) and Article 29 (transparency obligations) by lacking human oversight mechanisms and failing to disclose AI involvement in critical hiring decisions, risking discrimination and undermining workers' rights.", "context": "hiring"}
{"text": "A customer service AI chatbot automatically denies refund requests without human intervention, using opaque criteria that are not disclosed to users.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements) by failing to disclose AI decision-making processes and Article 29 (human oversight) by excluding human review for high-risk financial decisions. The lack of accountability mechanisms risks unfair treatment of consumers.", "context": "customer service"}
{"text": "A law enforcement agency deploys an AI system for facial recognition in public spaces to identify suspects, but the system operates without any human oversight mechanisms, automatically flagging individuals for surveillance without review by trained officers.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (transparency requirements for AI systems) by failing to inform individuals of AI-driven surveillance, and Article 29 (human oversight) by excluding human intervention in critical decision-making. The lack of oversight risks unlawful discrimination and erosion of privacy rights.", "context": "law enforcement"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention or review, relying solely on opaque algorithmic decisions.", "violation": true, "category": "human_oversight", "severity": "high", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (high-risk AI systems requiring transparency and risk assessment) and Article 29 (human oversight requirements) by depriving individuals of the right to challenge or appeal AI decisions, potentially leading to discriminatory outcomes and lack of accountability.", "context": "finance"}
{"text": "An AI system used by a recruitment agency automatically screens job applicants using unregulated personal data (e.g., age, gender) and makes final hiring decisions without allowing human oversight or transparency in its algorithmic processes.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 by processing personal data without proper data governance safeguards, and Article 29 by lacking human oversight and transparency requirements for high-risk AI systems in hiring. The system's opaque decision-making process undermines candidates' rights to contest automated decisions.", "context": "hiring"}
{"text": "A financial institution uses an AI-driven credit scoring system that automatically approves or denies loan applications without any human intervention, relying on biased historical data that systematically disadvantages minority groups.", "violation": true, "category": "human_oversight", "severity": "critical", "articles": ["Article 14", "Article 29"], "explanation": "This violates Article 14 (data governance requirements for high-risk AI systems) by using non-representative and biased data, and Article 29 (human oversight) by depriving users of the right to challenge or override AI decisions. The lack of transparency and accountability in financial decision-making poses significant risks to consumer rights and market fairness.", "context": "finance"}
{"text": "An e-commerce platform uses an AI system to analyze customer purchase history and browsing behavior without explicit consent, and fails to provide clear information about data usage, leading to unauthorized profiling and targeted advertising.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data through an AI system without ensuring transparency, data subject rights, and proper governance, as required for high-risk data processing under the EU AI Act.", "context": "e-commerce"}
{"text": "A law enforcement agency deploys an AI system for mass surveillance in public spaces using facial recognition technology without informing citizens, obtaining explicit consent, or providing mechanisms for data subjects to access or correct their biometric data.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates transparency, lawful processing, and data subject rights. The practice lacks informed consent, fails to ensure data subjects' ability to exercise their rights, and risks unauthorized processing of personal data without a clear legal basis.", "context": "law enforcement"}
{"text": "A manufacturing company uses an AI-based facial recognition system to monitor employee attendance without explicit consent, processing biometric data to track workers' presence on the factory floor.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data for identification purposes without ensuring data quality, transparency, or safeguards against discrimination. The system lacks informed consent and fails to meet the legal requirements for data governance in high-risk AI applications.", "context": "manufacturing"}
{"text": "An insurance company uses an AI system to assess risk and set premiums based on personal data such as socioeconomic status, which correlates with protected characteristics like race or gender, without providing transparency or allowing individuals to challenge the decisions.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which prohibits AI systems that process personal data in a way that could lead to discrimination, lack transparency, or fail to ensure data subject rights. The practice exploits biased data correlations to unfairly disadvantage specific groups, undermining fairness and accountability in insurance pricing.", "context": "insurance"}
{"text": "A social media platform uses an AI-powered recommendation system that collects and processes users' private messages and browsing history without explicit consent, then uses this data to create detailed psychological profiles for targeted political advertising without disclosing data usage practices.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure adequate data governance, transparency, and data subject rights. The AI system processes personal data without clear information about its use, undermines user control over their data, and exploits sensitive information for manipulative purposes without proper safeguards.", "context": "social media"}
{"text": "An AI-driven student performance prediction tool that uses unconsented personal data (e.g., social media activity, attendance records) to label students as 'at-risk' without transparency or mechanisms for data subject access or correction.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without explicit consent, lacking transparency about data usage, and failing to respect data subjects' rights to access, rectify, or delete their data, thereby undermining fundamental rights and data governance principles.", "context": "education"}
{"text": "A social media platform uses an AI system to analyze users' private messages and behavioral data without explicit consent, automatically generating targeted ads and sharing the data with third-party advertisers.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and user control over personal data. The AI system processes sensitive data without explicit consent, lacks meaningful user choice, and transfers data to third parties without proper safeguards, breaching data governance principles.", "context": "social media"}
{"text": "A social media platform uses an AI algorithm to analyze users", "violation": true, "category": "data_governance", "severity": "none", "articles": [], "explanation": "", "context": "social media"}
{"text": "An AI system used in hiring that analyzes candidates' facial expressions during video interviews to assess emotional stability and honesty, without informing candidates of the data processing or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing biometric data (facial expressions) without a lawful basis, transparency, or individual consent, failing to ensure data governance principles for sensitive data in hiring.", "context": "hiring"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on outdated and incomplete data sources, including deprecated public health statistics and unverified third-party databases, leading to inaccurate premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data quality and transparency in AI systems. The use of outdated and unverified data undermines the reliability of risk assessments, potentially leading to discriminatory outcomes and harm to policyholders' rights.", "context": "insurance"}
{"text": "A law enforcement AI system that automatically collects and processes biometric data from public surveillance cameras without informing individuals, allowing data subjects to access or correct their data, or obtaining explicit consent.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The system lacks mechanisms for individuals to exercise their rights to access, rectify, or delete their data, and does not provide clear information about data usage, violating the Act's data governance requirements.", "context": "law enforcement"}
{"text": "A legal services firm uses an AI system to analyze client data for risk assessments without implementing proper data governance measures, such as data minimization, transparency mechanisms, or security protocols for handling sensitive personal information.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 of the EU AI Act, which mandates strict data governance requirements for AI systems processing personal data. The lack of transparency, security safeguards, and data quality controls compromises the rights of data subjects and undermines trust in the legal services provided.", "context": "legal services"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders by analyzing non-essential personal data (e.g., social media activity) without explicit consent, leading to discriminatory premium rates.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data without lawful basis, transparency, or safeguards against discrimination. The AI system fails to ensure data minimization, accuracy, and respect for data subjects' rights, potentially exacerbating biases in insurance pricing.", "context": "insurance"}
{"text": "An insurance company uses an AI system to determine premium rates based on zip code data, which correlates with racial demographics, without informing policyholders or providing opt-out mechanisms.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data in a way that could lead to discrimination, lacks transparency, and fails to ensure fair treatment of individuals. The AI system uses indirect indicators of protected characteristics (race) to make decisions, which is prohibited under data governance requirements.", "context": "insurance"}
{"text": "A financial institution uses an AI-driven credit scoring system that aggregates customer data from unregulated third-party sources without transparency measures, leading to discriminatory loan approval decisions.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance, transparency, and quality. The system uses unverified data sources, risking biased outcomes and undermining fair access to financial services.", "context": "finance"}
{"text": "A smart city AI surveillance system uses facial recognition cameras in public spaces to monitor citizens' movements without explicit consent, retaining biometric data for indefinite periods without providing data subjects with access or deletion rights.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure transparency, data minimization, and data subject rights. The system processes sensitive biometric data without adequate safeguards, lacks mechanisms for individuals to access or delete their data, and retains information beyond necessary purposes.", "context": "smart city"}
{"text": "An insurance company uses an AI system to assess risk scores for policyholders based on incomplete and outdated personal data, leading to discriminatory premium calculations.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data quality requirements. The AI system uses inaccurate and incomplete data, which compromises fairness and undermines data governance principles in insurance risk assessment.", "context": "insurance"}
{"text": "An AI-driven student performance prediction tool used by schools collects and processes sensitive data (e.g., socio-economic background, attendance) without explicit consent, lacks transparency in its decision-making logic, and uses biased datasets leading to discriminatory outcomes in resource allocation.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure data governance principles: the AI system processes personal data without adequate safeguards (no explicit consent), lacks transparency in how data is used, and uses biased data that risks fundamental rights like non-discrimination and privacy. The lack of data quality and accountability mechanisms breaches the Act's requirements for fair and transparent data processing.", "context": "education"}
{"text": "An AI-powered traffic surveillance system in a city uses facial recognition cameras to monitor vehicles and drivers, collecting biometric data without explicit consent, and shares this data with third-party advertisers for targeted marketing.", "violation": true, "category": "data_governance", "severity": "critical", "articles": ["Article 10"], "explanation": "This violates Article 10 by processing personal data (biometric information) without adequate safeguards, transparency, or user consent. The system's use of data for purposes beyond traffic management (e.g., advertising) breaches data minimization and purpose limitation principles.", "context": "transportation"}
{"text": "A legal services firm uses an AI system to automate contract review, but the system is trained on unconsented personal data from previous client files, processed without data minimization or anonymization, and lacks transparency about how data is used.", "violation": true, "category": "data_governance", "severity": "high", "articles": ["Article 10"], "explanation": "This violates Article 10 by failing to ensure lawful data processing, transparency, and data subject rights. The AI system uses personal data without proper consent, lacks safeguards against data minimization breaches, and does not disclose data usage to users, undermining data governance principles.", "context": "legal services"}
